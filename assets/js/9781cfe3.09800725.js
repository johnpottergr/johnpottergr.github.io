"use strict";(self.webpackChunkjohnpottergr_github_io=self.webpackChunkjohnpottergr_github_io||[]).push([[8561],{4304:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});var i=n(7617),s=n(4848),o=n(8453);const r={title:"What is llms.txt and Why Does It Matter",date:new Date("2025-06-21T00:00:00.000Z")},a=void 0,l={authorsImageUrls:[]},c=[{value:"Its all about signals",id:"its-all-about-signals",level:2}];function h(e){const t={h2:"h2",p:"p",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:"LLMs are quickly changing how content gets discovered. Publishers and website owners are responding in kind, seeking to control how their content is used. With llms.txt being introduced - a proposed machine-readable file designed to communicate usage preferences to AI crawlers - content control become more feasible. The llm file faciliates AI info, much like how the robots.txt file faciliates traditional web indexing."}),"\n",(0,s.jsx)(t.h2,{id:"its-all-about-signals",children:"Its all about signals"}),"\n",(0,s.jsx)(t.p,{children:"The llms.txt file lets website owners signal how they want their content to be used when responding to LLM queries. For example, a publisher might specify that their content can be crawled, but note that it should not be used for long-term model training. Other publishers may allow only excerpts to be used in responses. Some publishers may even be more script."})]})}function d(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},7617:e=>{e.exports=JSON.parse('{"permalink":"/blog/6-21-2025-what-is-llms-txt","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-21-2025-what-is-llms-txt.md","source":"@site/blog/6-21-2025-what-is-llms-txt.md","title":"What is llms.txt and Why Does It Matter","description":"LLMs are quickly changing how content gets discovered. Publishers and website owners are responding in kind, seeking to control how their content is used. With llms.txt being introduced - a proposed machine-readable file designed to communicate usage preferences to AI crawlers - content control become more feasible. The llm file faciliates AI info, much like how the robots.txt file faciliates traditional web indexing.","date":"2025-06-21T00:00:00.000Z","tags":[],"readingTime":2.1,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"What is llms.txt and Why Does It Matter","date":"2025-06-21T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"The Strategy Shift From Static Docs to AI-Ready Assets","permalink":"/blog/6-22-2025-the-strategy-shift"},"nextItem":{"title":"Brand Visibility in LLMs Requires a New Kind of State","permalink":"/blog/6-22-2025-a-new-kind-of-state"}}')},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>a});var i=n(6540);const s={},o=i.createContext(s);function r(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);