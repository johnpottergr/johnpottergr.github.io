"use strict";(self.webpackChunkjohnpottergr_github_io=self.webpackChunkjohnpottergr_github_io||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/7-5-2025-blog-moving","metadata":{"permalink":"/blog/7-5-2025-blog-moving","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/7-5-2025-blog-moving.md","source":"@site/blog/7-5-2025-blog-moving.md","title":"My Blog Is Moving","description":"My blog is moving to my new venture at LLMvisibility.co. The site is nearly up, just working out some kinks.","date":"2025-07-05T00:00:00.000Z","tags":[],"readingTime":0.105,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"My Blog Is Moving","date":"2025-07-05T00:00:00.000Z"},"unlisted":false,"nextItem":{"title":"n8n vs. MCP for LLM Workflows","permalink":"/blog/7-2-2025-n8n-vs-mcp"}},"content":"My blog is moving to my new venture at LLMvisibility.co. The site is nearly up, just working out some kinks.\\n\x3c!--truncate--\x3e"},{"id":"/7-2-2025-n8n-vs-mcp","metadata":{"permalink":"/blog/7-2-2025-n8n-vs-mcp","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/7-2-2025-n8n-vs-mcp.md","source":"@site/blog/7-2-2025-n8n-vs-mcp.md","title":"n8n vs. MCP for LLM Workflows","description":"Building AI-powered workflows comes with many options, so it can feel overwhelming. The choice might come down to choosing something like n8n, which offers drag-and-drop automation and easily integrates with other tools, or MCP (Model Context Protocol), a standard for defining how LLMs interact with tools and data.","date":"2025-07-02T00:00:00.000Z","tags":[],"readingTime":3.66,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"n8n vs. MCP for LLM Workflows","date":"2025-07-02T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"My Blog Is Moving","permalink":"/blog/7-5-2025-blog-moving"},"nextItem":{"title":"The Blind Spot in Your Attribution, How to Turn ChatGPT Logs into Real Insight","permalink":"/blog/7-1-2025-blind-spot-attribution"}},"content":"Building AI-powered workflows comes with many options, so it can feel overwhelming. The choice might come down to choosing something like n8n, which offers drag-and-drop automation and easily integrates with other tools, or MCP (Model Context Protocol), a standard for defining how LLMs interact with tools and data.\\n\\nBoth approaches have their strengths. Depending on what you\u2019re trying to build, one might save you weeks of engineering time.\\n\\nTo understand this better, I\'m breaking down where each one excels and struggles, and how to decide which one is the best fit for your project.\\n\\n\x3c!--truncate--\x3e\\n\\n## What is n8n?\\nn8n is an open-source workflow automation platform that helps you connect apps without writing much code. It\'s similar to <a href=\\"https://make.com\\">Make</a>, but is self-hosted and highly customizable.\\n\\nOver the past year, n8n has steadily expanded into AI territory. You\u2019ll now find built-in nodes for:\\n\\n- Chat completion with OpenAI or Anthropic\\n- Embeddings generation\\n- Summarization pipelines\\n- Custom function nodes to process LLM output\\n\\nThis makes n8n very popular amond developers who want to:\\n\\n- Prototype AI workflows quickly\\n- Automate marketing tasks\\n- Orchestrate LLM calls alongside other SaaS tools like Slack or Airtable\\n\\nIf you\u2019re building an app that needs to move data between systems and it employs AI along the way, n8n would seem to be the fastest route to getting to proof of concept.\\n\\n## What is MCP?\\nI was really enamored with Model Context Protocol (MCP) earlier this year. MCP is highly structured approach to defining how an LLM interacts with outside tools. It\'s not focused on workflows. Instead it sets the rules for:\\n\\n- The capabilities of a model (\u201cwhat tools can it call?\u201d)\\n- The schema of each tool input and output\\n- How the model can reason about when to use which tool\\n\\nMCP sits closer to the agent end of the spectrum. It\u2019s built to help developers build sophisticated AI assistants. You\'ll see MPC being used when there is a need to:\\n\\n- Select and invoke tools dynamically\\n- Handle multi-step reasoning\\n- Keep track of context across multiple user queries\\n\\nMCP gains attention among any team working on LLM orchestration frameworks, such as those inspired by LangChain. If you want to build an AI agent that behaves consistently over time, MCP provides is your tool. It provides what a typical workflow automation tool cannot.\\n\\n## Where n8n works best\\nn8n will meet your needs if you:\\n\\n- Need to prototype quickly without concerns about infrastructure\\n- Want something visual (diagrams) for non-developers\\n- Are focused on practical automation (like notifications) rather than complex reasoning\\n-Seek to integrate dozens of APIs out of the box\\n\\nFor example, if you want to set up an LLM to summarize support tickets from Zendesk and send them to Slack every morning, n8n is yout tool\\n\\n## Where MCP excels\\nMCP starts to make more sense when you:\\n\\n- Are building multi-step, context-aware agents\\n- Need to enforce strict contracts around tool calls\\n- Care about making your model outputs more predictable\\n- Building production-grade workflows that require consistent reasoning\\n\\nFor instance, if you\u2019re designing a financial assistant that can:\\n\\n- Retrieve account balances\\n- Run projections\\n- Compose a detailed response\\n- Track all steps in a traceable way\\n\\nThis is where MCP\u2019s structured definitions can help you avoid bad logic and guarantee your models behave reliably.\\n\\n## Should You Pick One Over the Other?\\nIn practice, these tools serve different audiences.\\n\\nIf you want LLM-powered automations that can be deployed quickly and **evolve over time** with minimal friction, n8n is compelling. It\u2019s practical and easy to share across your team.\\n\\nIf you\u2019re thinking about LLM agents that need careful control, tool selection, and traceability, MCP is a better bet.\\n\\n## Lasr words\\nIf you\u2019re trying to stand out in the AI space, consider reviewing both. But if you can only go deep on one, n8n is the safer bet for visibility.\\n\\nThe reason is simple. Companies love practical automations they can adopt immediately, and n8n is able to deliver them.\\n\\nMCP is still important, especially for teams that need to build enterprise-grade assistants. But the adoption curve has not hit the same stride.\\n\\n## Bottom line:\\nIf you want to showcase practical LLM workflows and help others ship them, start with n8n. You can always layer in MCP later as your projects get more complex."},{"id":"/7-1-2025-blind-spot-attribution","metadata":{"permalink":"/blog/7-1-2025-blind-spot-attribution","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/7-1-2025-blind-spot-attribution.md","source":"@site/blog/7-1-2025-blind-spot-attribution.md","title":"The Blind Spot in Your Attribution, How to Turn ChatGPT Logs into Real Insight","description":"Most companies are still treating web analytics like it\u2019s 2015. They set up GA4 or Adobe, tag their campaigns, and trust the dashboards to tell them how people discover and engage with what we publish. But LLMs have changed everything in the past year, and it\u2019s quietly rewriting the rules of attribution.","date":"2025-07-01T00:00:00.000Z","tags":[],"readingTime":4.01,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"The Blind Spot in Your Attribution, How to Turn ChatGPT Logs into Real Insight","date":"2025-07-01T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"n8n vs. MCP for LLM Workflows","permalink":"/blog/7-2-2025-n8n-vs-mcp"},"nextItem":{"title":"9 Reasons Why Your Content Falls Flat with AI","permalink":"/blog/6-29-2025-why-content-falls-flat"}},"content":"Most companies are still treating web analytics like it\u2019s 2015. They set up GA4 or Adobe, tag their campaigns, and trust the dashboards to tell them how people discover and engage with what we publish. But LLMs have changed everything in the past year, and it\u2019s quietly rewriting the rules of attribution.\\n\\nLLMs are the new gateway to your website. Web users are asking questions in chat interfaces that pull in pieces of your content to help form answers. While great for brand visibility, it\u2019s problmeatic for traditional analytics. Since these interactions often don\u2019t fire the JavaScript that standard web analytics depends on, you have a flaw in your reporting.\\n\\nHere\'s an example: Someone asks ChatGPT about the best way to calibrate lab equipment. The model finds an excerpt from your guide and follows up with a link. The user clicks it, skims a section, and leaves. In GA4, you\u2019ll see either nothing at all or a tiny blip of Direct traffic you can\u2019t attribute. Over time, that missing traffic adds up.\\n\\nIn the end, if you can\u2019t measure LLM behavior, you can\u2019t make informed decisions about what\u2019s driving conversions.\\n\\n\x3c!--truncate--\x3e\\n\\n## So where does that leave you?\\nDan Hinckley of Go Fish Digital <a href=\\"https://www.linkedin.com/feed/update/urn:li:activity:7345428861028851712/\\">notes there is one place you can turn to</a>. It turns out your server logs already have the story you\u2019re looking for. They see every request, no matter how it was initiated.\\n\\nWhen ChatGPT sends a user to your site, it identifies itself with a special user agent:\\n```\\nswift\\nMozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko); compatible; ChatGPT-User/1.0; +https://openai.com/bot\\n```\\n\\nThis isn\u2019t some hypothetical curiosity. Real companies are seeing a significant volume of traffic in their logs from this user agent. In some cases, those visits convert far better than average. But if you never look at your logs, you\u2019ll never know.\\n\\n## Making use of visitor logs\\nHere\u2019s how to start bridging the gap between your logs and your marketing attribution:\\n\\n### 1. Pull the Logs into a Usable Format\\nFirst, get access to your raw server logs. Depending on your hosting environment, you might find them in Apache or Nginx log files, or stored by your CDN. You\u2019ll want at least a few weeks of data to start seeing patterns.\\n\\nTools like Screaming Frog Log File Analyzer (see below) or GoAccess can help you parse and filter the logs without writing a bunch of custom scripts. Look specifically for entries containing ChatGPT-User.\\n\\n<img src=\\"/img/logs.png\\" alt=\\"Screaming Frog\\" width=\\"800\\"/>\\n\\n## 2. Build a Simple Report\\nOnce you isolate these records, create a spreadsheet or dashboard that answers a few core questions:\\nWhich URLs are being accessed?\\n\\n- How often?\\n- On what days?\\n- From which IP addresses or locations (if available)?\\n\\nThis report becomes your first real view into which pages and topics ChatGPT is using in conversations.\\n\\n### 3. Look for patterns in topic demand\\nSay you notice that one blog post gets ten times more ChatGPT visits than any other page. That\u2019s a clear signal that your content on that topic is resonating in AI-powered discussions.\\nUse this insight to guide decisions:\\n\\n- Should you create a follow-up article or a deeper resource?\\n- Can you add a clear call to action to capitalize on this attention?\\n- Are there related topics you could cover to build authority?\\n\\nThis is where log data stops being an attribution headache and becomes a competitive advantage.\\n\\n### 4. Connect log insights to outcomes\\nIf your CRM or e-commerce platform tracks referral data, try to match visits from the ChatGPT user agent to conversions or leads. You may find that AI-referred traffic has a higher intent than other channels.\\n\\nEven if you can\u2019t perfectly connect every touchpoint, you\u2019ll start to see that these \u201cinvisible\u201d visitors are real prospects worth understanding.\\n\\n### 5. Bring other teams into the loop\\nHave your content team can use these insights to prioritize updates and new articles. Your sales team might reference popular topics in outreach or proposals. Product teams can spot recurring questions that suggest gaps in documentation.\\nWhen everyone can see what ChatGPT is sending traffic to, you\u2019re better equipped to plan strategically.\\n\\n## Final Thoughts\\nChatGPT is already changing how people discover and evaluate information. If you\u2019re relying on standard analytics alone, you\u2019re missing the big picture. Server logs might feel traditional, but they\u2019re the only place where you follow the full trail of these interactions.\\n\\nThis as an opportunity. The companies that figure out how to measure and act on LLM-driven engagement first will be the ones that get ahead. Everyone else will be wondering why conversions are dropping and dashboards are coming up empty.\\n\\nIf you haven\u2019t looked at your logs in a while, now\u2019s the time. You might be more influential in the AI era than you think."},{"id":"/6-29-2025-why-content-falls-flat","metadata":{"permalink":"/blog/6-29-2025-why-content-falls-flat","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-29-2025-why-content-falls-flat.md","source":"@site/blog/6-29-2025-why-content-falls-flat.md","title":"9 Reasons Why Your Content Falls Flat with AI","description":"You\u2019ve probably noticed that some of your content seems to vanish into the void. It never seems to surface in search or meet with enthusiasm from your audience. It\u2019s not bad luck: AI models that rank and retrieve content are particular about how they process what you write. If you don\u2019t pay attention to how they work, your content will end up buried.","date":"2025-06-29T00:00:00.000Z","tags":[],"readingTime":3.51,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"9 Reasons Why Your Content Falls Flat with AI","date":"2025-06-29T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"The Blind Spot in Your Attribution, How to Turn ChatGPT Logs into Real Insight","permalink":"/blog/7-1-2025-blind-spot-attribution"},"nextItem":{"title":"Building Online Authority Through Embeddings Intelligence","permalink":"/blog/6-27-2025-building-authority-through-embeddigs"}},"content":"You\u2019ve probably noticed that some of your content seems to vanish into the void. It never seems to surface in search or meet with enthusiasm from your audience. It\u2019s not bad luck: AI models that rank and retrieve content are particular about how they process what you write. If you don\u2019t pay attention to how they work, your content will end up buried.\\n\\nHere, i walk through the biggest issues that will keep your content from being found and understood by AI...and what you can do to fix them.\\n\\n\x3c!--truncate--\x3e\\n\\n## 1. Weak starts leave AI guessing\\n**The pain point:** Most writers ease into the topic, thinking they\u2019re building suspense or context. In reality, AI models treat your intro as the signal for what the entire page is about. A slow buildup tells the model nothing and costs you rankings.\\n\\n**What to do instead:** Lead with your main insight or answer right up front. Don\u2019t bury it behind anecdotes or a long setup.\\n\\n## 2. A messy structure confuses an LLM\\n**The pain point:** When content rambles without clear sections, AI struggles to figure out what belongs where. Without headings every few hundred words, your work looks like a wall of text.\\n\\n**How to fix it:** Use short blocks and clear subheadings every 200\u2013300 words. Oh, and Maintain consistent formatting. Think of your page as a series of labeled bins. You want to make it easy for AI to sort your ideas.\\n\\n## 3. Generic formats get ignored\\n**The pain point:** Vague titles and formats don\u2019t match what AI is trained to recognize. If your page doesn\u2019t look like a guide or how-to, it will gets skipped over in favor of content that does.\\n\\n**Better approach**: Use familiar formats like \u201cWhat is [Topic]?\u201d, \u201cHow to [Do Something],\u201d or \u201cBest Tools for [Need].\u201d These patterns are instantly understood and prioritized by AI.\\n\\n## 4. One-off posts miss the bigger picture\\n**The pain point:** Publishing stand-alone articles might feel efficient, but AI values clusters of related content. Provide supporting pieces around your core topic so your work has more context and relevance.\\n\\n**Solution:** Build 3\u20135 related posts that connect back to your main idea. It signals authority and reinforces meaning to AI.\\n\\n## 5. Complex language makes AI hallucinate\\n**The pain point:** Long sentences and academic jargon confuse AI. In the end, it can only guess what you mean. Put another way, the more complex your phrasing, the less confident the model feels matching your content to queries.\\n\\n**How to improve:** Write simply. Use the same words your audience would search for. Clarity always beats cleverness.\\n\\n## 6. Inconsistent keywords break the chain\\n**The pain point:** If you use different terms across your website and social channels, you dilute your signal. AI can\u2019t reliably connect the dots if your keywords keep changing.\\n\\n**Quick fix:** Pick your core terms and repeat them across all channels, lke your site, social posts, and metadata.\\n\\n## 7. Overused angles blend into the noise\\n**The pain point:** Even familiar topics get stale when you rehash the same angles everyone else uses. AI is tuned to spot unique takes paired with recognizable patterns.\\n\\n**What to try:** Bring in a timely hook or unexpected viewpoint that reframes your message without losing clarity.\\n\\n### 8. Disorganized ideas lose momentum\\n**The pain point:** When your ideas jump around, AI can\u2019t figure out the logical thread. It processes one concept at a time. If you scatter them, it loses track.\\n\\n**What helps:** Outline your content before you draft it. Each idea should flow naturally into the next.\\n\\n## 9. Partial answers leave readers hanging\\n**The pain point:** Some content only tackles half the problem. AI prefers pieces that address the full context, because they feel more complete and trustworthy.\\n\\n**Your move:** Answer the main question thoroughly. Then close the loop by addressing what comes next, so your reader (and the model) feel satisfied.\\n\\n## Final thoughts\\nIf your content isn\u2019t performing, it might not be because it\u2019s unhelpful. It\u2019s likely because AI can\u2019t recognize its value. Structure your writing to align with how models process and rank information. Doing so will make it easier for your ideas to surface, stand out, and drive results."},{"id":"/6-27-2025-building-authority-through-embeddigs","metadata":{"permalink":"/blog/6-27-2025-building-authority-through-embeddigs","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-27-2025-building-authority-through-embeddigs.md","source":"@site/blog/6-27-2025-building-authority-through-embeddigs.md","title":"Building Online Authority Through Embeddings Intelligence","description":"Building online authority requires chasing backlinks, tweaking keywords, and manually engaging multiple platforms just to stay visible. But that playbook is changing (who has the patience?). I\'m putting togther a new system\u2014the Embeddings-Powered Content Intelligence Engine to brings automation, semantic analysis, and smart content distribution together for the sake of LLM brand visibility.","date":"2025-06-27T00:00:00.000Z","tags":[],"readingTime":1.905,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Building Online Authority Through Embeddings Intelligence","date":"2025-06-27T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"9 Reasons Why Your Content Falls Flat with AI","permalink":"/blog/6-29-2025-why-content-falls-flat"},"nextItem":{"title":"LLM Reverse Engineering with RAG to Probe AI Search Behavior","permalink":"/blog/6-26-2025-embeddings-and-RAG"}},"content":"Building online authority requires chasing backlinks, tweaking keywords, and manually engaging multiple platforms just to stay visible. But that playbook is changing (who has the patience?). I\'m putting togther a new system\u2014the Embeddings-Powered Content Intelligence Engine to brings automation, semantic analysis, and smart content distribution together for the sake of LLM brand visibility.\\n\\nEmbeddings is at the heart of this system. These are vector-based representations of language that capture the meaning and context of words, not just their appearance. They help us understand why some content connects and spreads, while other posts fall flat.\\n\\n\x3c!--truncate--\x3e\\n\\nThis technology can help you analyze the \u201csemantic fingerprint\u201d of high-performing content, so you can apply these insights to your content strategy.\\n\\nI like to think of it akin to correlating content with topical fit. Which goes to the heart of audience attraction. Instead of guessing what might resonate, you\'re working from a blueprint of what already does.\\n\\n## Making It Real\\nHere\u2019s what that looks like in practice.\\n\\n- An LLM such as **DeepSeek V3** reviews real-time data from social platforms, identifies trends and tone gaps in your current content, and uses embeddings to make precise comparisons.\\n\\n- **Agent S2**, a web automation tool, collects the content that\u2019s performing well across different platforms. It navigates sites like a human would, learning from each pass to get better at spotting high-engagement material and posting at the right time.\\n\\n- **n8n** ties these tools together\u2014triggering the LLM to draft a response, deploying Agent S2 to post it, and tracking how people respond.\\n\\nYou could say they work together as a team:\\n<img src=\\"/img/huddle.png\\" alt=\\"AI Huddle\\" width=\\"800\\"/>\\n\\nCombining these tools goes beyond optimization. It creates a system for putting your brand in the right conversations with the right tone on a consistent basis. If someone mentions your company in a podcast transcript or blog comment, the system can surface that mention, craft a thoughtful reply, and publish it. All without manual review.\\n\\nThe focus isn\u2019t on gaming SEO. It\u2019s on becoming visible through genuine engagement and semantic relevance.\\n\\n## Looking forward\\nAs tools like DeepSeek and xAI\u2019s APIs evolve, this kind of content intelligence will become ore accessible. It offers brands a scalable way to build trust, generate visibility, and establish authority without adding a ton more tasks."},{"id":"/6-26-2025-embeddings-and-RAG","metadata":{"permalink":"/blog/6-26-2025-embeddings-and-RAG","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-26-2025-embeddings-and-RAG.md","source":"@site/blog/6-26-2025-embeddings-and-RAG.md","title":"LLM Reverse Engineering with RAG to Probe AI Search Behavior","description":"Note: RAG is a technique that improves an LLM\'s capabilities by integrating them with external data sources.","date":"2025-06-26T00:00:00.000Z","tags":[],"readingTime":2.09,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"LLM Reverse Engineering with RAG to Probe AI Search Behavior","date":"2025-06-26T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Building Online Authority Through Embeddings Intelligence","permalink":"/blog/6-27-2025-building-authority-through-embeddigs"},"nextItem":{"title":"LLM Reverse Engineering with Embeddings","permalink":"/blog/6-25-2025-reverse-engineering-with-embeddings"}},"content":"*Note: RAG is a technique that improves an LLM\'s capabilities by integrating them with external data sources.*\\n\\n**RAG (Retrieval-Augmented Generation) systems** can be used to simulate and test how LLMs retrieve content. They don\'t just probe what a model knows, but what it displays when someone asks a question.\\n\\n\x3c!--truncate--\x3e\\n\\n<img src=\\"/img/rag.png\\" alt=\\"RAG\\" width=\\"800\\"/>\\n*Image From K21Academy.com*\\n\\n**So here\'s a simple experiment.** Use ChatGPT\u2019s search mode to run a query, copy the full text of the cited sources, and load them into a local RAG pipeline built with n8n. From there, start asking questions against the dataset and watch what the model pulls up. You can make small tweaks like changing headings, rephrasing sections, or adding new pages to see what ripple effects occur.\\n\\n## What you can learned by rebuilding the retrieval stack\\nThe first big insight here is that LLMs won\u2019t retrieve entire webpages, they will pull chunks... of paragraphs and sections. If the right terms aren\u2019t in the right block of text, the model won\u2019t select it\u2014even if the broader page is relevant.\\n\\nNext, you\'ll note that the Q&A structures perform really well even if they\u2019re not FAQs. If a page has summaries, question-like subheadings, or bullet-point answers, the model is much more likely to grab and reuse that text.\\n\\nBut keywords still matter. Not so much across the page but in the chunks. If a keyword or phrase isn\u2019t embedded in the local context, an LLM might skip it entirely. In other words, the idea of keyword density is not the focus here.\\n\\n## Why RAG Matters for Reverse Engineering\\nRAG  gives you a lab environment to test how AI might respond to real-world questions. You control the content and the prompt. You also get to see which chunks rise to the top.\\n\\nIt\u2019s not a perfect mirror of live LLM behavior, but it\u2019s helpful enough to reveal certain patterns:\\n\\n- Which types of structure improve extractability\\n\\n- What phrasing improves retrievability\\n\\n- How small edits shift the model\u2019s attention\\n\\nRAG is a smart way to test your content\'s influence without having to access the internal workings of a proprietary LLM.\\n\\n## What Comes Next\\nRetrievability is just as important as relevance here. You may write brilliant, on-topic content but still be invisible to AI if the structure doesn\u2019t fit with chunk-level extraction.\\n\\nNext up in this series, I\u2019ll look at how prompts, citations, and retrieval context shape what LLMs decide to surface\u2014and how that impacts your ability to show up in chat-based interfaces."},{"id":"/6-25-2025-reverse-engineering-with-embeddings","metadata":{"permalink":"/blog/6-25-2025-reverse-engineering-with-embeddings","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-25-2025-reverse-engineering-with-embeddings.md","source":"@site/blog/6-25-2025-reverse-engineering-with-embeddings.md","title":"LLM Reverse Engineering with Embeddings","description":"If you\u2019ve ever asked ChatGPT a question and found a competitor\u2019s blog quoted back to you, you\u2019re probably wondering how to get YOUR content into that response box.","date":"2025-06-25T00:00:00.000Z","tags":[],"readingTime":2.37,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"LLM Reverse Engineering with Embeddings","date":"2025-06-25T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"LLM Reverse Engineering with RAG to Probe AI Search Behavior","permalink":"/blog/6-26-2025-embeddings-and-RAG"},"nextItem":{"title":"How Agent S2 and n8n Expand What LLMs Can See and Do","permalink":"/blog/6-24-2025-agents2-n8n-and-llms"}},"content":"If you\u2019ve ever asked ChatGPT a question and found a competitor\u2019s blog quoted back to you, you\u2019re probably wondering how to get YOUR content into that response box.\\n\\nTraditional SEO might help but is not the full answer. LLMs don\u2019t crawl pages in the way search engines do. They embed them, converting your content into numerical representations. Its how they capture a site\'s meaning, tone, and topic relationships.\\n\\nIn other words, LLMs don\'t index your keywords, they interpret your concepts.\\n\\nThat\u2019s why embedding analysis can be used to reverse engineer how AI models understand your site. You don\'t need to guess what they might say about your content, you can look directly at the data they\'re using to generate those answers.\\n\\n\x3c!--truncate--\x3e\\n\\n## What Are Embeddings\\nAt a high level, embeddings are \\"vectors\u2014high-dimensional coordinates\\" that represent your content\'s meaning. Pages that cover similar themes or serve similar intents tend to cluster closely in this space, even if they use very different words. LLMs use this vector space to locate the next most relevant piece of content.\\n\\nWhen you see AI-generated answers that include links, quotes, or summaries from web content, those outputs are shaped by their semantic proximity, not exact keyword matches. If your content doesn\'t cluster well around a topic, or if it overlaps too much with other pages on your site, it\'s hard for your site to display.\\n\\n## Auditing Your Own Embeddings\\nRecently, tools like Screaming Frog have made it possible to extract embeddings from your site in short order. If you use an API connection to OpenAI or another LLM provider, you can crawl your site, convert each page into its embedded form, and visualize the results in what\u2019s called a <a href=\\"https://www.screamingfrog.co.uk/seo-spider/tutorials/how-to-identify-semantically-similar-pages-outliers/\\">Content Cluster Diagram</a>.\\n\\n<img src=\\"/img/cluster.png\\" alt=\\"Content-Cluster-Diagram\\" width=\\"800\\"/>\\n\\nThis diagram shows how your content is semantically distributed. It can help you determine if all your topic pages tight and clearly defined, or if some are too similar. You can use the diagram to see if some pages are disconnected from your core focus. A visual map gives you an AI\u2019s-eye view of how your site looks in embedding space.\\n\\n## Why It Matters\\nEmbedding-based analysis does a few things that traditional SEO audits miss:\\n\\n- Reveals semantic duplication, even when titles differ\\n\\n- Flags outlier pages that don\u2019t align with your topical authority\\n\\n- Highlights opportunities for consolidation or internal linking\\n\\n- Provides clues into how LLMs might classify your content\\n\\nIt\u2019s especially powerful for marketers who want their content to show up in tools like ChatGPT, Claude, or Perplexity\u2014not just Google.\\n\\n## What Comes Next\\nLLM Reverse Engineering can be revealing, helping you understand how AI models display content. Next, I\'ll focus on an entirely different way to reverse engineer LLM output.\\nThe more your understand how AI sees the web, the better position you\'re to leverage it."},{"id":"/6-24-2025-agents2-n8n-and-llms","metadata":{"permalink":"/blog/6-24-2025-agents2-n8n-and-llms","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-24-2025-agents2-n8n-and-llms.md","source":"@site/blog/6-24-2025-agents2-n8n-and-llms.md","title":"How Agent S2 and n8n Expand What LLMs Can See and Do","description":"LLMs most impressive capabilities still revolve around generating text. But when it comes to navigating complex software interfaces or handling on-screen workflows, they need help. Here\'s where Simular\'s Agent S2 shakes things up/","date":"2025-06-24T00:00:00.000Z","tags":[],"readingTime":3.31,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"How Agent S2 and n8n Expand What LLMs Can See and Do","date":"2025-06-24T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"LLM Reverse Engineering with Embeddings","permalink":"/blog/6-25-2025-reverse-engineering-with-embeddings"},"nextItem":{"title":"Integrating Agent S2 with n8n for Marketing Automation","permalink":"/blog/6-23-2025-Integrating-Agent-S2-with-n8n"}},"content":"LLMs most impressive capabilities still revolve around generating text. But when it comes to navigating complex software interfaces or handling on-screen workflows, they need help. Here\'s where Simular\'s Agent S2 shakes things up/\\n\\nAgent S2 is an open-source autonomous agent able to visually interpret and interact with user interfaces. Paired with n8n, a flexible open-source automation tool, Agent S2 can be orchestrated in workflows that tie together APIs, apps, and UIs. Obviously, Using this tools in combination can dramatically expand LLM\'s power and visibility.\\n\\nWhat are the implcations?\\n\\n\x3c!--truncate--\x3e\\n\\n## The LLM Visibility Gap\\nLLMs excel at processing language. They can summarize reports, generate code, and answer customer queries. But they\u2019re blind to real-world interfaces. A model might know how to log into a system in theory, but it can\u2019t see the login button or detect error messages. Recognizing a pop-up blocking its progress isn\'t even part of the equation.\\n\\nWithout visibility into what\u2019s actually happening in an interface, LLMs are left guessing. This is one of the key limitations in deploying LLMs for hands-on automation.\\n\\n## Agent S2 for Eyes and Hands\\nAgent S2 fixes this by acting as a virtual user. It can see the screen, understand visual elements, and carry out complex UI interactions. Its generalist-specialist architecture is especially helpful here, as it remembers and learns from past sessions.\\n\\nBetter yet, pairing Agent S2 with n8n workflows can serve as part of a larger automation pipeline. It might activate in response to an event, for instance (say, an alert trigger). That\u2019s fairly powerful. But what happens when we bring an LLM into the loop?\\n\\n## Making LLMs Aware of the Interface\\nReal-time UX knowledge is where the possibilities get interesting.\\n\\nAgent S2 logs its actions so: where it clicked, what elements were visible, what succeeded or failed. These logs can then be passed to an LLM. This gives the model access to real execution context, which it wouldn\'t normally have.\\n\\nFor example:\\n\\n- Did the Submit button disappear after the first click?\\n- Was a confirmation message displayed?\\n- Did the AI agent get stuck in a CAPTCHA loop?\\n\\nKnowing these inputs can help an LLM generate more accurate summaries and recommendations for the next run. It could redefine CRO (conversion rate optimization).\\n\\n## From Theory to Reality\\nIn traditional setups, LLMs operate on what users say or provide. With Agent S2, they can respond to what actually happened. That creates a new loop of intelligent automation:\\n\\n- n8n triggers Agent S2 to execute a UI task.\\n- Agent S2 logs its steps and outcomes.\\n- The log is passed to an LLM for analysis or decision-making.\\n- The LLM adapts the next instruction set or flags issues.\\n\\nIn addition to improving automation accuracy, it also gives marketing teams better info on how automation behaves in real environments.\\n\\n## Rethinking Observability\\nA longer-term implication is generation of synthetic training data. Being able to accurately simulate customer journeys means Agent S2 can generate rich interaction histories that LLMs can fine-tune and use to inform marketers over time. You\u2019re moving from giving the LLM data to giving it experience.\\n\\nWith retained learning taking place, you can now take practical steps to eliminate inbound marketing obstacles:\\n\\n- Customer support help (what workflows cause the most friction?)\\n- Marketing funnel analysis (where do automated journeys drop off?)\\n- User interface optimization (where does the agent struggle that a user might too?)\\n\\n## LLMs Will Soon Have Real-World Awareness\\nLLMs will likely remain text-first models for awhile. But that doesn\u2019t mean they will stay isolated from the user interfaces where work gets done.\\n\\nPairing an intelligent S2 agent with orchestration tools like n8n, and feeding the outputs into an LLM could create a hybrid system where:\\n\\n- The agent sees and acts\\n- The LLM reasons and adapts\\n- The orchestrator connects and automates\\n\\nThe result is a more informed automation\u2014system, one that understand context not just from data inputs, but from lived execution."},{"id":"/6-23-2025-Integrating-Agent-S2-with-n8n","metadata":{"permalink":"/blog/6-23-2025-Integrating-Agent-S2-with-n8n","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-23-2025-Integrating-Agent-S2-with-n8n.md","source":"@site/blog/6-23-2025-Integrating-Agent-S2-with-n8n.md","title":"Integrating Agent S2 with n8n for Marketing Automation","description":"Agent S2 is a new <a href=","date":"2025-06-23T00:00:00.000Z","tags":[],"readingTime":4.19,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Integrating Agent S2 with n8n for Marketing Automation","date":"2025-06-23T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How Agent S2 and n8n Expand What LLMs Can See and Do","permalink":"/blog/6-24-2025-agents2-n8n-and-llms"},"nextItem":{"title":"The Strategy Shift From Static Docs to AI-Ready Assets","permalink":"/blog/6-22-2025-the-strategy-shift"}},"content":"<a href=\\"https://www.simular.ai/articles/agent-s2\\">Agent S2</a> is a new <a href=\\n\\"https://github.com/simular-ai/Agent-S\\">open-source framework</a> that allows AI to interact with software like a human. It can see the screen, click buttons, and type. It also offers state-of-the-art performance in multi-step tasks, edging out OpenAI and Anthropic in benchmarks.\\n\\nBeyond the stats, what sets it apart is how it learns: by breaking down tasks into sub-tasks handled by specialist modules and remembering what worked or didn\u2019t. This dynamic knowledge base allows the agent to improve over time.\\n\\nFor marketers, this opens the door to real automation of complex workflows. It\'s not based on rule-based triggers, but performs adaptive action sequences that evolve.\\n\\n<img src=\\"/img/state-of-art.png\\" alt=\\"Agent-S2\\" width=\\"800\\"/>\\n\\n\x3c!--truncate--\x3e\\n\\n## Why Agent S2 Matters for Marketers\\nAgent S2 highlights the fact you don\'t need to rely on big-tech for innovation. S2 is open-source, which means smaller teams can use, customize, and build on it. But the key point here is that it can learn from experience.\\n\\nTraditional marketing automation doesn\u2019t improve unless someone reprograms it. An agent like S2, on the other hand, might discover that your checkout has a hidden pop-up\u2014and fix its own script to account for it. That kind of autonomy turns a one-off automation into a smarter, evolving assistant.\\n\\nIt\u2019s also capable of fetching data online while navigating app interfaces, so it can both act in a CRM and pull competitor pricing in real time. Combininng interface manipulation plus live knowledge obviously makes it a pretty powerful tool.\\n\\n## Why n8n?\\n<a href=\\"https://n8n.io/\\">n8n</a> is a flexible open-source automation tool that lets you build workflows connecting different apps. It\u2019s part no-code and part code, good for teams who want more customization than Zapier offers. When paired with Agent S2, n8n handles the orchestration (when to do something, what to pass along) while the agent does the heavy lifting in apps with no API.\\n\\nFor example, a workflow could be:\\n- Trigger: New lead arrives\\n- n8n gathers context\\n- Agent S2 logs into a site, pulls a report, updates another platform\\n- n8n handles follow-up: sends an email or logs success\\n\\nS2 does what most automation tools can\u2019t, it interacts with systems that don\u2019t offer integration simply by mimicking a user.\\n\\n<img src=\\"/img/agentS2.png\\" alt=\\"Agent-S2\\" width=\\"800\\"/>\\n\\n## Practical Use Cases\\n### Cross-Platform Marketing Tasks\\n**Reporting:** Agent S2 can open Google Analytics, apply filters, export data, grab lead data from your CRM, merge in Sheets, then draft an email with the results. n8n can schedule it all. Yikes!\\n\\n**Social Posting:** Posting across LinkedIn, Instagram, and others often involves tedious logins. S2 can handle that manually via UI, even if APIs are lacking or unreliable. So tempting.\\n\\n**Data Syncing:** From uploading CSVs to verifying data in multiple systems, Agent S2 can automate web forms that would normally be hand-entered.\\n\\n### Customer Journey Testing\\n**User Flow Simulation**: If you want to know where users get stuck, S2 can simulate a customer\u2019s visit\u2014clicking through checkout, hitting roadblocks, and logging what goes wrong. (are just built CRO-focused software stack that does this, this makes it obsolete)\\n\\n**Multi-Touchpoint Analysis**: By logging into different platforms, S2 can collect user activity across email, support, and site flows. Then you can use an LLM to analyze where friction arises. I foresee the field of competitive intelligence getting a revival.\\n\\n**Training AI Models with Synthetic Data**\\nIf you need to train a model but lack user data, S2 can simulate interactions, generating logs that serve as training data for LLMs to learn customer behavior patterns. I suspect this capability is probably more important than it sounds.\\n\\n**Future: AI Concierge**\\nThis category is speculative, but realistic. Imagine a chatbot that, instead of just chatting, uses Agent S2 to take real action. Think booking a flight. Combine that with n8n\u2019s logic and you could offer live assistance without needing custom integrations.\\n\\n## Getting Started\\n**Explore the tools:** Try setting up n8n and experiment with Agent S2\u2019s GitHub repo. It\'s easy enough to read about it. Start using it (telling this to myself too).\\n\\n**Identify pain points**: Look at your manual workflows to remedy. Anything that is multi-step, needs to work across platforms, or involves systems with no APIs is a good candidate.\\n\\n**Start small:** Have n8n trigger S2 to visit a page or take a screenshot. Once that works, try expanding gradually.\\n\\n**Monitor + Train**: Early runs might fail, but S2 learns. With repeated use, it improves.\\n\\n**Stay secure**: Use sandbox accounts and fail-safes until you trust the system.\\n\\n\\n## Final Word\\nAgent S2 shows what\u2019s now possible with autonomous agents: they can see, act, and learn. Combine it with n8n and you can orchestrate advanced automations that go beyond what most platforms offer. It\u2019s not all plug-and-play yet, but the pieces are here.\\n\\nMarketers who willing to experiment will gain a serious advantages in their industry. Don\'t wait for the perfect solution, think about what you could build today.\\n\\nIf you\'re interested in more details about this (this blog post is a slimmed down version of some research), contact me to receive more info."},{"id":"/6-22-2025-the-strategy-shift","metadata":{"permalink":"/blog/6-22-2025-the-strategy-shift","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-22-2025-the-strategy-shift.md","source":"@site/blog/6-22-2025-the-strategy-shift.md","title":"The Strategy Shift From Static Docs to AI-Ready Assets","description":"Most companies today have plenty of documentation but not much content. They have pdfs, slide decks, and product manuals. Even case studies buried in download libraries that have yet to see daylight. It\u2019s not that they don\u2019t have answers; it\u2019s that the answers are locked away, invisible to the LLMs people now use to ask questions.","date":"2025-06-22T00:00:00.000Z","tags":[],"readingTime":2.765,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"The Strategy Shift From Static Docs to AI-Ready Assets","date":"2025-06-22T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Integrating Agent S2 with n8n for Marketing Automation","permalink":"/blog/6-23-2025-Integrating-Agent-S2-with-n8n"},"nextItem":{"title":"What is llms.txt and Why Does It Matter","permalink":"/blog/6-21-2025-what-is-llms-txt"}},"content":"Most companies today have plenty of documentation but not much content. They have pdfs, slide decks, and product manuals. Even case studies buried in download libraries that have yet to see daylight. It\u2019s not that they don\u2019t have answers; it\u2019s that the answers are locked away, invisible to the LLMs people now use to ask questions.\\n\\nIt\'s a lost opportunity to generate greater brand visibility. Especially when it comes to answering middle-of-funnel questions.\\n\\n## Make the Mental Shift\\nIt doesn\'t have to be this way. When it comes to client engagement, it might be helpful to stop thinking like SEOs and start thinking like machines. Google\u2019s crawler and an LLM\u2019s transformer are very different beasts. Google might index a PDF. An LLM will ignore it entirely. What to do?\\n\\n\x3c!--truncate--\x3e\\n\\nIf you want to get more mileage out of your documentation - like LLM mentions - start here:\\n\\n- Convert PDFs into HTML-based knowledge pages. Static downloads are invisible to most LLMs. Formatting your content as web-native makes it indexable and referenceable.\\n\\n- Add structured data to every page. Use schema types like FAQPage, TechArticle, and Product to help machines interpret what your content is and where it fits.\\n\\n- Link product pages to supporting documentation. Glossary-based anchor links are a simple way to create relationships that both users and AI systems can follow.\\n\\n- Showcase real authors and contact options. Adding bios and CTAs supports E-E-A-T signals (Experience, Expertise, Authoritativeness, Trustworthiness), which influence how search engines and LLMs track your credibility.\\n\\n## Reusing Existing Docs: A Low-Cost Win\\nIf you\u2019ve already invested in whitepapers, manuals, and case studies, you\u2019re sitting on a goldmine for LLM visibility. It just needs to be reformatted. This isn\'t a call to create more content. It\u2019s a call to reuse what you already have in a format that machines can read.\\n\\nOne local example stands out. <a href=\\"https://www.psgdover.com/blackmer\\">Blackmer</a>, a Grand Rapids-based manufacturer, has an <a href=\\"https://www.psgdover.com/blackmer/download-library/compressor-bulletins\\">extensive download library</a> filled with brochures, case studies, catalogs, and bulletins. It\'s content that\u2019s ripe for transformation into AI-readable formats.\\n\\n<img src=\\"/img/psg-dover.png\\" alt=\\"PSG Dover\\" width=\\"800\\"/>\\n\\nEven without pursuing external AI exposure, the same assets could be repurposed internally. Using <a href=\\"https://medium.com/@elisowski/mcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288\\">Model Context Protocol (MCP) tooling</a>, their support teams could reveal these answers directly in Slack or Salesforce instead of fumbling through a search bar.\\n\\nBut here\u2019s the problem: the company has a policy against using AI. Which is a bit like trying to compete in e-commerce while banning websites. It\'s going to lead to painful, incremental obsolescence. Think edge customers calling it quits because getting answers takes too long. Death by a thousand cuts.\\n\\n## The Business Case Will Come (Eventually)\\nMost companies won\u2019t care about LLM visibility until they have to. Until the bottom line reveals that inbound leads are down, support costs are up, or customers are quoting competitors\' AI-powered answers instead of theirs. But those who take the leap early will start seeing it in deflection rates, faster time-to-resolution, and fewer \u201cWhere can I find\u2026\u201d questions cluttering internal channels.\\n\\nAnd I\'m only talking about restructuring dusty documentation for modern interfaces. The branding benefits that accrue from LLM visibility are multifold.\\n\\nI guess it really depends are whether you think LLMs are just another marketing channel or part of a more important transformation. They\'re a new layer of knowledge access."},{"id":"/6-21-2025-what-is-llms-txt","metadata":{"permalink":"/blog/6-21-2025-what-is-llms-txt","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-21-2025-what-is-llms-txt.md","source":"@site/blog/6-21-2025-what-is-llms-txt.md","title":"What is llms.txt and Why Does It Matter","description":"LLMs are quickly changing how content gets discovered. Publishers and website owners are responding in kind, seeking to control how their content is used. With llms.txt being introduced - a proposed machine-readable file designed to communicate usage preferences to AI crawlers - content control become more feasible. The llm file faciliates AI info, much like how the robots.txt file faciliates traditional web indexing.","date":"2025-06-21T00:00:00.000Z","tags":[],"readingTime":2.1,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"What is llms.txt and Why Does It Matter","date":"2025-06-21T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"The Strategy Shift From Static Docs to AI-Ready Assets","permalink":"/blog/6-22-2025-the-strategy-shift"},"nextItem":{"title":"Brand Visibility in LLMs Requires a New Kind of State","permalink":"/blog/6-22-2025-a-new-kind-of-state"}},"content":"LLMs are quickly changing how content gets discovered. Publishers and website owners are responding in kind, seeking to control how their content is used. With llms.txt being introduced - a proposed machine-readable file designed to communicate usage preferences to AI crawlers - content control become more feasible. The llm file faciliates AI info, much like how the robots.txt file faciliates traditional web indexing.\\n\\n## Its all about signals\\nThe llms.txt file lets website owners signal how they want their content to be used when responding to LLM queries. For example, a publisher might specify that their content can be crawled, but note that it should not be used for long-term model training. Other publishers may allow only excerpts to be used in responses. Some publishers may even be more script.\\n\\n\x3c!--truncate--\x3e\\n\\nThe lms.txt is an inspired idea if you believe the legal concerns about data scraping, copyright, and compensation are mounting (they are). As generative AI tools combine and sift through the vast swaths of online info, publishers risk losing traffic and attribution if their original work is displayed without credit (or even a link).\\n\\nSince their is no standardized opt-out mechanism here, website owners cannot negotiate how their content is handled. AI platforms have not been helpful in this regard, ignoring the issue and reluctant to enforce boundaries consistently.\\n\\n## Lets cheer for transparency\\nThe new llms.text standard is a structured way to help the public define those preferences. The result is more transparency and control in the relationship between content creators and AI platforms. With llms.txt, sites can point to a shared framework that crawlers can check before viewing data. All of which leads to less content misuse and ambiguity.\\n\\nThe new txt standard is just starting to become known, so adoption is still in its early stages. But the idea represents a key step toward governance in the age of AI. It reflects a growing recognition that web content is not just freely available for the taking. Itt\'s also valuable. It give\'s site owners a way to say \u201cyes,\u201d \u201cno,\u201d or \u201conly on these terms\u201d  - setting clearer norms for AI data practices going forward.\\n\\nThe idea seems to be catching on, because it speaks to boundaries. It\'s helping publishers participate in the AI ecosystem on their own terms. And it\'s encouraging AI companies to respect those terms. Even if you\'re not a publisher, the trend is bound to create an environment where our personal data will also have to be respected. The scrapers are on notice."},{"id":"/6-22-2025-a-new-kind-of-state","metadata":{"permalink":"/blog/6-22-2025-a-new-kind-of-state","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-22-2025-a-new-kind-of-state.md","source":"@site/blog/6-22-2025-a-new-kind-of-state.md","title":"Brand Visibility in LLMs Requires a New Kind of State","description":"If you\u2019ve ever worked with developers to improve website behavior, like handling pop-ups, forms, or product filters, they were probably using React. It\u2019s a popular tool for building modern websites (to say the least). But when too many pieces of a site need to work together, the process gets chaotic fast.","date":"2025-06-21T00:00:00.000Z","tags":[],"readingTime":3.57,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Brand Visibility in LLMs Requires a New Kind of State","date":"2025-06-21T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"What is llms.txt and Why Does It Matter","permalink":"/blog/6-21-2025-what-is-llms-txt"},"nextItem":{"title":"What It Takes To Build An LLM Visibility Content Audit Tool","permalink":"/blog/6-20-2025-llm-visibility-content-audit-tool"}},"content":"If you\u2019ve ever worked with developers to improve website behavior, like handling pop-ups, forms, or product filters, they were probably using <a href=\\"https://www.builder.io/blog/react-component-library\\">React</a>. It\u2019s a popular tool for building modern websites (to say the least). But when too many pieces of a site need to work together, the process gets chaotic fast.\\n\\nDevelopers help resolve this by turning to <a href=\\"https://redux.js.org/\\">Redux</a> - a Javascript tool that pulls scattered data into one place and makes it easier to coordinate. Its not an elegant process but it produces consistency and control, especially when in comes to interactive experiences. It\'s also why <a href=\\"https://www.linkedin.com/in/mantcz/\\">\\nMichael Antzack</a> believes the <a href=\\"https://www.linkedin.com/posts/mantcz_react-redux-llm-activity-7342829633370775552-ut7i\\">centralized state wins</a>.\\n\\nThat same logic is now starting to show up in how brands think about visibility and coordination in the age of LLMs.\\n\\n\x3c!--truncate--\x3e\\n\\n<img src=\\"/img/redux.png\\" alt=\\"Select Sheet\\" width=\\"800\\"/>\\n\\nMost brands that experiment with LLMs today are thinking in static terms, like a chatbot that answers FAQs or a plugin that pulls from their help docs. Even a one-time prompt injected into a marketing tool. These are isolated efforts useful but a bit shallow. They don\u2019t account for the where the user is in their customer journey, or even the broader goals of the brand.\\n\\nLLM visibility for brands is not going to stay still. The focus will shift from just showing up in the LLM to showing up in context. In other words, LLM awareness of the customer\u2019s past behavior, current intent, and what needs to happen next. While speculation is great, what use does this theorizing have for brands today? This is where the Redux analogy gets interesting.\\n\\n## A Shift Toward Agent-Driven Coordination\\nLLMs are moving beyond simple prompt-and-response tools. They\u2019re evolving into agents that operate as autonomous or semi-autonomous systems. That means they can plan, retrieve data, take actions, and even coordinate with other agents. The AI agent won\'t just answer your question about a return policy, it will initiate the return, updates your order history, and sends a Slack alert to your fulfillment team.\\n\\nTo enable that kind of behavior, you\'ll need more than a knowledge base. You\'ll need to gain centralized, accessible, real-time state of the customer relationship.\\n\\nIn practical terms, this means building an LLM-ready interface layer that is able to track and feeds dynamic data into the agent. Tools like n8n, which automate workflows across apps, could act as connective tissue here. They would make sure the agent sees updates in CRM, inventory, analytics, and support systems in near real time.\\n\\n## Will LLMs Evolve to Handle This?\\nProbably. We\u2019re already seeing early moves toward multi-modal inputs, tool use, memory, and planning. n8n\'s are exploding among early adopters. In a year or two, it may not be unusual for a customer to browse, ask questions, and purchase within a branded agent interface powered by LLMs.\\n\\nBut that can\u2019t happen unless the brand builds the right data scaffolding. If there\u2019s no visibility into product catalog changes, loyalty status, or campaign eligibility, the AI won\u2019t be able to take meaningful action. It will fall back to generic responses, just like a broken UI reverts to static HTML. So there\'s a lot of work to be done.\\n\\n## What This Means Right Now\\nIf your brand is just getting into LLMs, don\u2019t limit your thinking to surface-level visibility like prompt optimization or FAQ coverage. I know, it\'s already asking a lot to move on from SEO to focus on LLM Visibility. But first followers \'get the worm\'.\\nStart by treating your data layer as the interface. There is no roadmap here but you can begin by asking:\\n\\n- What does the AI see about this customer?\\n- What decisions could it make with that context?\\n- How could automation tools coordinate the next step?\\n\\nYes, it\u2019s a little like replacing email with chat but it\'s more than that. It\u2019s a shift from fragmented, one-off messaging to stateful, intelligent, AI-driven interactions. And it will require rethinking where your brand\u2019s \u201cstate\u201d lives, that is - what data your AI systems can actually see and act on.\\n\\nAnticipating these moves can help you stay ahead, especially as others are already laying the groundwork to be more customer-responsive. Because bfore long, AI agents won\u2019t be chatting with your customers, they\u2019ll be acting on their behalf."},{"id":"/6-20-2025-llm-visibility-content-audit-tool","metadata":{"permalink":"/blog/6-20-2025-llm-visibility-content-audit-tool","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-20-2025-llm-visibility-content-audit-tool.md","source":"@site/blog/6-20-2025-llm-visibility-content-audit-tool.md","title":"What It Takes To Build An LLM Visibility Content Audit Tool","description":"The Goal","date":"2025-06-20T00:00:00.000Z","tags":[],"readingTime":3.055,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"What It Takes To Build An LLM Visibility Content Audit Tool","date":"2025-06-20T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Brand Visibility in LLMs Requires a New Kind of State","permalink":"/blog/6-22-2025-a-new-kind-of-state"},"nextItem":{"title":"Why Probabilistic Visibility Is the New Page One","permalink":"/blog/6-20-2025-probabilitic-visibility"}},"content":"## The Goal: Build a Stack That Performs:\\n- **LLM citation scans:** to identify where your brand is being referenced in AI-generated answers across LLM tools, and how often it appears.\\n- **Prompt recall tests:** to evaluate how well your content shows up in response to common AI prompts, and whether that content is accurate.\\n- **Linkless mention tracking:** to spot brand mentions that appear in forums, summaries, and AI outputs even when there\u2019s no backlink.\\n- **Crawlability for AI bots:** to check if your content is accessible to AI-oriented crawlers and isn\u2019t blocked by rendering issues or robots.txt settings.\\n- **Pull in**: search-generated citations and prompt-level results using browser automations and n8n scripts.\\n\\n## The Recipe\\n### \ud83e\uddea 1. Prompt Recall Tests\\nTest whether your content appears in response to relevant prompts.\\n\\n**Manual Testing:**\\n- ChatGPT Plus ($20/mo) \u2013 GPT-4o for manual recall tests\\n\\n**Automation (optional):**\\n- Playwright or Puppeteer \u2013 Browser automation for simulating prompt entry across tools\\n- n8n \u2013 For scheduling and orchestrating prompt runs\\n- Claude API or OpenAI API \u2013 To score results for accuracy and brand inclusion\\n\\n\x3c!--truncate--\x3e\\n\\n### \ud83d\udcce 2. LLM Citation Scans\\nCheck if your brand is cited in LLM answers and where it\u2019s sourced from.\\n\\n**Citation-exposing LLMs:**\\n- Perplexity Pro \u2013 Shows citations and sources\\n- You.com \u2013 Another citation-enabled tool\\n- Bing Copilot \u2013 Sometimes includes sources\\n\\n**Scraping tools (for non-API access):**\\n- Playwright/Puppeteer (same as above) \u2013 To extract citations from UI\\n- n8n or Zapier \u2013 To automate scraping and logging\\n\\n### \ud83d\udd0d 3. Linkless Mention Tracking\\nMonitor forums, summaries, and AI outputs for brand mentions without backlinks.\\n\\n**Tools:**\\n- Mention.com, Brand24, or Talkwalker Alerts \u2013 Track unlinked mentions online\\n- Google Alerts \u2013 Free mention tracking\\n- Reddit API or Pushshift \u2013 To pull brand mentions in forums\\n- Twitter/X API (if needed) \u2013 Paid tiers\\n- Optionally, GPT-4 or Claude \u2013 To detect \u201cimplied\u201d brand mentions from raw text\\n\\n### \ud83e\udd16 4. AI Bot Crawlability Checks\\nVerify if AI crawlers can access your content and see it rendered correctly.\\n\\n**Tools:**\\n- Screaming Frog SEO Spider or Sitebulb \u2013 Crawlability + render testing\\n- Manual robots.txt review \u2013 Look for blocks on GPTBot, Google-Extended, ClaudeBot, etc.\\n- Playwright\u2013 For rendering and testing dynamic content (JS-heavy pages)\\n\\n### \ud83d\udd01 5. Workflow Automation & Logging\\nStitch everything together and log results.\\n\\n- n8n (cloud or desktop) \u2013 Workflow automation\\n- Airtable, Supabase, or [Google Sheets] \u2013 Store test results and citations\\n- Retool or Streamlit \u2013 Optional dashboards\\n\\n### \ud83d\udcc4 6. Reporting & Output (Optional)\\nGenerate audit reports for stakeholders or clients.\\n\\n**Tools:**\\n- Jinja2 (templating engine for HTML/PDF)\\n- Pandas \u2013 For data processing and report formatting\\n- WeasyPrint or PDFKit \u2013 Turn HTML into PDFs\\n\\n## Side note on Linkless Mentions per ChatGPT\\nLinkless mention tracking is important for LLM visibility because modern language models are trained not just on pages with backlinks but on the full context of language, including brand names mentioned without links. In short: if your brand shows up in the training or inference data\u2014even without a link, it can influence whether you\'re surfaced in answers.\\n\\nHere\u2019s why that matters, in practical terms:\\n\\n\ud83e\udde0 1. LLMs Learn from Language Context, Not Just Links\\nUnlike Google\u2019s PageRank, LLMs aren\u2019t built on link graphs. They \\"understand\\" brands through:\\n\\n- Raw mentions in text (even without a URL)\\n- Surrounding context (how people describe you)\\n- Frequency and tone of mentions\\n\\nSo a brand mentioned often in AI-generated articles, Reddit comments, or summaries, even without backlinks, gets semantically associated with direct mail, marketing automation, etc. This raises its chances of showing up in relevant LLM responses."},{"id":"/6-20-2025-probabilitic-visibility","metadata":{"permalink":"/blog/6-20-2025-probabilitic-visibility","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-20-2025-probabilitic-visibility.md","source":"@site/blog/6-20-2025-probabilitic-visibility.md","title":"Why Probabilistic Visibility Is the New Page One","description":"The era of static rankings is coming to an end. If your SEO strategy is still focused on capturing the number one position for a specific keyword, you\u2019re preparing for a bygone era. AI driven search using LLMs is reshaping the landscape.","date":"2025-06-20T00:00:00.000Z","tags":[],"readingTime":2.025,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Why Probabilistic Visibility Is the New Page One","date":"2025-06-20T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"What It Takes To Build An LLM Visibility Content Audit Tool","permalink":"/blog/6-20-2025-llm-visibility-content-audit-tool"},"nextItem":{"title":"GSR - A New Metric for Measuring Brand Visibility in AI-Generated Results","permalink":"/blog/6-19-2025-GSR-a-new-metric"}},"content":"The era of static rankings is coming to an end. If your SEO strategy is still focused on capturing the number one position for a specific keyword, you\u2019re preparing for a bygone era. AI driven search using LLMs is reshaping the landscape.\\n\\nNow, brand visibility in LLMs isn\u2019t a straightforward outcome; it\u2019s a probabilistic one.\\n\\nWhen someone requests a product recommendation from an LLM, the response hinges on much more than just the text of the query.\\n\\nUser intent, context, and even minor phrasing differences can drastically influence which brands get recommended. This is because there\u2019s no one size fits all answer for something like \u201cWhat\u2019s the best mattress?\u201d or \u201cWhat\u2019s the top marketing tool?\u201d Hundreds of different recommendations could come forth based on who is doing the asking, as well as how and when they ask.\\n\\nWelcome to what <a href=\\"https://www.linkedin.com/in/garrettsussman/\\">Garrett Sussman</a> calls Probabilitic Visibility\\n\\n\x3c!--truncate--\x3e\\n\\nThe new reality requires a different content and brand strategy. Rather than trying to funnel everything through a single point of entry, you\'ll need to build resilience across many potential pathways.\\n\\nInstead of thinking about optimizing for a keyword here or a page there, think about creating networks of content that interact to lead someone to your desired end point. Being cited means more than just one place and one source. It involves content that can speak to various buyer personas, not just the primary target.\\n\\nPersonas are all about context - how your brand appears to someone researching for the first time versus someone on the brink of making a purchase.\\n\\nSo.... each content piece should be considered part of a larger visibility strategy. You should always ask yourself if the page you are creating could serve as a reference for someone down the line. In other words, your content should affirm:\\n\\n- Can it accommodate various depths of detail?\\n- Is it straightforward to cite?\\n- Does it align with the different ways people might ask about the same thing?\\n\\nBeing visible on multiple sites, in different formats, and through varying tones and entry points gives you a better shot at appearing in LLM generated responses.\\n\\nYou are not trying to control one narrow channel; you are expanding your presence across the whole field.We are moving into a phase where making content discoverable is fluid and adaptable. To achieve this, we need to think not just like search engine optimizers but more so like systems designers."},{"id":"/6-19-2025-GSR-a-new-metric","metadata":{"permalink":"/blog/6-19-2025-GSR-a-new-metric","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-19-2025-GSR-a-new-metric.md","source":"@site/blog/6-19-2025-GSR-a-new-metric.md","title":"GSR - A New Metric for Measuring Brand Visibility in AI-Generated Results","description":"The Generative Search Ratio (GSR) is a new metric that developer Todd Gray has proposed to assess how discoverable a brand is within environments driven by large language models (LLMs).","date":"2025-06-19T00:00:00.000Z","tags":[],"readingTime":3.045,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"GSR - A New Metric for Measuring Brand Visibility in AI-Generated Results","date":"2025-06-19T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Why Probabilistic Visibility Is the New Page One","permalink":"/blog/6-20-2025-probabilitic-visibility"},"nextItem":{"title":"Citation Score, A New Metric for Brand Visibility in the Age of AI","permalink":"/blog/6-19-2025-think-like-a-systems engineer"}},"content":"The Generative Search Ratio (GSR) is a new metric that <a href=\\"https://www.linkedin.com/in/toddegray/\\">developer Todd Gray</a> has proposed to assess how discoverable a brand is within environments driven by large language models (LLMs).\\n\\nAs businesses contend with the shift from traditional search methods to those powered by generative AI, they must now ensure visibility not just in Google rankings but also in the synthesized responses provided by LLM tools like ChatGPT and others.\\n\\n## What is GSR?\\nThe GSR serves as a way to quantify this new kind of digital presence, helping brands understand their positioning in this emerging search landscape. It basically assesses the relationship between your visibility in large language model (LLM) responses and your performance in traditional SEO.\\n\\nThe basic formula is: GSR = (GEO Score \xd7 Visibility Weight) / SEO Score\\n\\n\x3c!--truncate--\x3e\\n\\n### Here\'s how the components break down:\\n\\n- **GEO Score:** The percentage of key prompts where your brand appears in an AI generated response.\\n\\n- **Visibility Weight:** A modifier that adjusts for how prominent the mention is, based on prompt type.Core prompts (e.g., \\"best CRM for startups\\") receive more weight than niche ones (e.g.,\\"top CRM that works with an internal Postgres database\\").\\n\\n- **SEO Score:** How well your brand performs in the keyword rankings you care about\u2014usually pulled from search analytics or third party tools. These two metrics combined give a rough sense of whether your brand is keeping up, falling behind, or pulling ahead in this new era of AI driven search results\\n\\nTogether, these factors produce a single number that helps assess whether your brand\u2019s AI presence is keeping up with\u2014or surpassing\u2014your SEO presence.\\n\\n## Interpreting GSR\\n- **GSR \u2265 1.0** \u2192 Your brand has a strong presence in AI generated content. It appears as though your brand ranks higher in AI answers than it does in traditional organic search results.\\n\\n- **GSR 0.5 \u2013 1.0** \u2192 You are moderately visible to LLMs. Your content is discoverable, but it is not prominent enough in AI responses to ensure that you are being \\"seen\\" by these models.\\n\\n- **GSR < 0.5** \u2192 You have good SEO and poor visibility to LLMs. You are not being picked up by the LLMs that generate AI responses, which may necessitate changes in your content structure, clarity, or authoritative signals. (most brands are here?)\\n\\n- **GSR > 1.0 with low SEO** \u2192 You are doing well in AI generated responses but underperforming in traditional search results. It is time to delve into the basics of SEO.\\n\\n**Low GSR and low SEO** \u2192 You\'re essentially invisible on both fronts. It is time for a comprehensive strategy reset to ensure full visibility.\\n\\n## Not All Prompts Are Equal\\nOne of the most insightful aspects of the GSR metric is how it differentiates between types of prompts. As Todd Gray points out, not all citations generated by LLMs are equally valuable:\\n\\n- Core Prompts (broad, high-intent questions) acarry the most weight.\\n\\n- Conditional Prompts (requiring specific parameters) provide real value and are worth tracking, but they are not as impactful as the more general prompts. They\'re context-dependent.\\n\\n- Niche/Web Prompts are less impactful but still worth tracking for completeness.\\n\\nThis granularity helps the GSR account for meaningful discoverability in the real world, not just raw mention counts.\\n\\n## Limitations and Next Steps\\nGSR is still an emerging concept. It requires:\\n\\n- A reliable prompt library across core/niche/conditional types\\n\\n- Access to AI-generated responses, from APIs or scraping)\\n\\n- Standardized SEO performance benchmarks\\n\\nLLM Visibility methodology is still being refined, but as we move from links to language, we\'ll need new metrics that follow. So GSR might be the first of many."},{"id":"/6-19-2025-think-like-a-systems engineer","metadata":{"permalink":"/blog/6-19-2025-think-like-a-systems engineer","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-19-2025-think-like-a-systems engineer.md","source":"@site/blog/6-19-2025-think-like-a-systems engineer.md","title":"Citation Score, A New Metric for Brand Visibility in the Age of AI","description":"When someone asks ChatGPT, Perplexity, or Claude a question, where does the answer come from and how often does it come from you?","date":"2025-06-19T00:00:00.000Z","tags":[],"readingTime":2.39,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Citation Score, A New Metric for Brand Visibility in the Age of AI","date":"2025-06-19T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"GSR - A New Metric for Measuring Brand Visibility in AI-Generated Results","permalink":"/blog/6-19-2025-GSR-a-new-metric"},"nextItem":{"title":"A New App Makes It Easier to Spot Content Opportunities","permalink":"/blog/6-18-2025-deyan-georgiev"}},"content":"When someone asks ChatGPT, Perplexity, or Claude a question, where does the answer come from and how often does it come from you?\\n\\nAs LLMs replace search engines for top-of-funnel research and product discovery, a new visibility layer is emerging: citations. AI-generated answers increasingly include footnotes, source links, or inline references to websites, articles, and documentation. These citations form a kind of modern backlink but with different mechanics and consequences.\\n\\nAnd that brings us to a new idea: Citation Score.\\n\\n## What Is Citation Score?\\nCitation Score is a way to measure how frequently and how prominently your brand, product, or content is cited by LLMs across a set of relevant queries. Think of it like domain authority, but instead of measuring how many other sites link to you, it measures how often LLMs mention or reference your content as part of their synthesized answers.\\n\\nA basic version might include:\\n\\n- **Citation Frequency:** How many times your content appears across 100 high-intent questions?\\n\\n- **Citation Position:** Are you the first link? Buried in footnotes? Cited inline?\\n\\n- **Citation Context:** Are you cited for facts, how-to instructions, product comparisons, or definitions?\\n\\nOver time, these could be modeled into a visibility index that SEO teams and brand strategists can track.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why This Matters\\nRanking #1 in search doesn\u2019t mean much if ChatGPT answers the question directly and never cites you. Similarly, showing up in SGE (Google\u2019s Search Generative Experience) summaries or Perplexity citations could drive more indirect influence, even without clicks.\\n\\nCitation Score gives marketers a way to quantify this influence. It can also help content teams reverse-engineer what types of assets are likely to be surfaced by LLMs: well-structured docs, clear product explanations, or high-authority third-party coverage.\\n\\n## Lessons from Academia and Publishing\\nInterestingly, this kind of modeling has already taken off in other domains. Academic publishing has spent years refining metrics like:\\n\\n- h-index (how often a researcher is cited and how widely their work is distributed)\\n\\n- co-citation networks (who gets cited alongside whom)\\n\\n- altmetrics (social and public engagement around citations)\\n\\n<img src=\\"/img/citation.png\\" alt=\\"Citation Map\\" width=\\"800\\"/>\\n\\nImagine applying those to LLM visibility:\\n\\n- **Co-citation Score:** What brands are consistently cited next to yours? Are you always mentioned alongside competitors or in a league of your own?\\n\\n- **Contextual Trust Graphs:** If multiple LLMs cite your docs for a given topic, does that amplify downstream visibility in future model updates?\\n\\n- **Temporal Citation Maps:** Are you gaining or losing answer share across product categories or technical terms?\\n\\nThese are more than thought experiments, they\'re prototypes waiting to be built.\\n\\n## A New Visibility Layer\\nCitation Score won\u2019t replace SEO. But it changes the focus, replacing \\"how you perform in search\\" with \\"do you exist in the answer\\". As AI agents become the default research layer for consumers, that\u2019s a visibility gap too important to ignore."},{"id":"/6-18-2025-deyan-georgiev","metadata":{"permalink":"/blog/6-18-2025-deyan-georgiev","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-18-2025-deyan-georgiev.md","source":"@site/blog/6-18-2025-deyan-georgiev.md","title":"A New App Makes It Easier to Spot Content Opportunities","description":"As AI tools become more acccessible, app development has become easier. SEO professionals are starting to apply their expertise to build practical applications. One such professional is Deyan Georgiev from Toro Rank. I recently asked him to discuss an innovative app he built.","date":"2025-06-18T00:00:00.000Z","tags":[],"readingTime":2.945,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"A New App Makes It Easier to Spot Content Opportunities","date":"2025-06-18T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Citation Score, A New Metric for Brand Visibility in the Age of AI","permalink":"/blog/6-19-2025-think-like-a-systems engineer"},"nextItem":{"title":"The Emergence of the LLM Visibility Specialist","permalink":"/blog/6-17-2025-The LLM-visibility-expert"}},"content":"As AI tools become more acccessible, app development has become easier. SEO professionals are starting to apply their expertise to build practical applications. One such professional is <a href=\\"https://www.linkedin.com/in/dgeorgiev87/\\">Deyan Georgiev</a> from <a href=\\"https://tororank.com\\">Toro Rank</a>. I recently asked him to discuss an innovative app he built.\\n\\n## What does your tool do, and why should we care? (spoiler: we should)\\n<a href=\\"https://toro-rank-content-gap.streamlit.app/\\">The tool I built</a> addresses two problems I see often while working with clients. Businesses are missing content opportunities and accidentally hurting their SEO with off-topic content just to get more traffic, or their SEO guy/agency can validate their invoice. *Interviewer\'s note:* Use <a href=\\"https://serper.dev\\">Serper API</a> with app.\\n\\n\x3c!--truncate--\x3e\\n\\nInstead of guessing what to write about, it shows you exactly what real people are asking that competitors aren\'t answering well. It scrapes Reddit for actual user questions (with upvote counts), grabs Google\'s autocomplete suggestions, and analyzes how thin competitor content is. Then it maps everything visually so you can clearly see the gaps and opportunities.\\n\\nThe second part audits your entire website to find pages that don\'t match your main topic, which sounds boring can be a huge problem. I\'ve found sites where 40% of their content was completely off-topic, basically telling Google they don\'t know what their business is about.\\n\\n<img src=\\"/img/toro.png\\" alt=\\"Select Sheet\\" width=\\"800\\"/>\\n\\n## Why did you create it?\\nI had the idea of building something similar for a long time, but I didn\u2019t quite have the time to sit down and do it properly. That was until I started working with a client who had a massive website, but their blog content was completely messed up topic-wise.\\n\\nTheir blog posts were all over the place, and there was no connection to each other or to their main business. The site was too big to manually review every article, so I needed a way to quickly identify which content was actually hurting them.\\n\\nThat\'s how the website audit feature came about. I built it because I needed to solve that problem ASAP.\\n\\nOnce I could see their content landscape clearly, the next challenge was helping them target better topics that actually made sense for their niche. That\'s when I added the 3D vector analysis and content gap discovery to find opportunities within their actual expertise area instead of random topics, or tools\u2019 KW suggestions with high traffic potential and low difficulty.\\n\\nEspecially with AI mode and AIO in other countries, we should stop believing in keyword estimates given by the big SEO tools. Because that\u2019s what they are - estimates, not hard data. Google Keyword Planner gives some insights on keyword volume and such, but I think it\u2019s a bit bloated, to say the least. Therefore, most content strategies are built on assumptions.\\n\\n### Yes, Toro Rank Meets A Real Need\\n\\nThe tool I built isn\u2019t a game-changer, but at least it uses real data - actual questions from Reddit users, real searches from Google autocomplete, and actual competitor analysis. No guessing, no estimates, no assumptions.\\n\\nThe Reddit piece is especially powerful because upvotes tell you which problems people actually care about. If 200 people upvoted a question about \\"my smart TV OS is slow\\" but no competitor has a decent guide on it, that\'s free traffic sitting there.\\n\\nI\u2019m giving the tool away for free because good content strategy shouldn\'t only be available to people who can afford the expensive tools. This is in fact the sixth free tool I built and shared for free, and there will be more to come, so stay tuned."},{"id":"/6-17-2025-The LLM-visibility-expert","metadata":{"permalink":"/blog/6-17-2025-The LLM-visibility-expert","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-17-2025-The LLM-visibility-expert.md","source":"@site/blog/6-17-2025-The LLM-visibility-expert.md","title":"The Emergence of the LLM Visibility Specialist","description":"What Is an LLM Visibility Specialist?","date":"2025-06-17T00:00:00.000Z","tags":[],"readingTime":3.24,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"The Emergence of the LLM Visibility Specialist","date":"2025-06-17T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"A New App Makes It Easier to Spot Content Opportunities","permalink":"/blog/6-18-2025-deyan-georgiev"},"nextItem":{"title":"ChatGPT evaluates my Clearscope-style tool","permalink":"/blog/6-17-2025-clearscope-tool-progress"}},"content":"## What Is an LLM Visibility Specialist?\\nAn LLM Visibility Specialist is someone who helps content get recognized by large language models (LLMs), such as ChatGPT, Claude, and Google AI Overviews. They combine writing, strategy, and lightweight technical tools to improve how frequently a brand is mentioned in AI-generated answers.\\n\\nThis new role is gradually emerging as search behavior shifts toward LLM platforms. It builds on traditional content writing and SEO but goes a step further by focusing on how to structure content so that AI tools select it as a reliable source.\\n\\n## Why It Matters for Content Writers\\nFor content writers, this shift means your job doesn\u2019t end at publishing what\u2019s useful. The real opportunity lies in learning how LLMs interpret your content. From there, you\u2019ll have to change how you write, structure, and track performance to fit that behavior. If someone asks ChatGPT about a problem your content solves, your goal is to make sure it\u2019s your content that gets cited.\\n\\nTop-of-funnel and middle-of-funnel content is the primary focus here, but bottom-of-funnel content may not be far behind. This blog post is the first one I\u2019ve written with this focus in mind. And it probably won\u2019t be the last.\\n\\n\x3c!--truncate--\x3e\\n\\n### Let Me Be Clear\\nThe average LLM visitor is worth 4.4x the average traditional organic search visitor. Not only that, but ChatGPT results only overlap with 12% with Google SERP results (<a href=\\"https://speakerdeck.com/joshbly/josh-blyskal-profound-we-analyed-10000-000-ai-search-results-dot-dot-dot\\">Josh Blyskal, Profound</a>). So LLM visibility isn\u2019t just another SEO trend. It\u2019s a big change in how information flows and who receives credit when someone asks an LLM a question.\\n\\n<img src=\\"/img/overlap.png\\" alt=\\"Select Sheet\\" width=\\"800\\"/>\\n\\n## Content Is Still King\\nSure, the articles, guides, product pages, and snippets you publish are what LLMs are trained to reference. If the goal is to show up in an LLM answer feed, someone still has to write the source material.\\n\\nBut it\u2019s not about writing more content. It\u2019s primarily about structuring content so LLMs can quote it, interpret it, and trust it.\\n\\nThis means:\\n- Writing in \u201cquotable chunks\u201d with clear headers and bullet points\\n- Anticipating the types of prompts users will enter into AI tools\\n- Using consistent phrasing and NLP-friendly structures\\n- Ensuring crawlability not just for a Google bot but for any LLM crawlers\\n- Creating content that answers real questions\\n\\n## Where the Job Starts to Expand\\nIf you stop at publishing helpful content, that\u2019s ok. You\u2019re still in the game, but you\u2019re playing defense. Visibility specialist take the oppositie track by focusing on how to  track, guide, and shape how that content appears in LLM outputs.\\n\\nThis includes:\\n- **Prompt testing:** Determining whether your content appears when AI is asked key questions\\n- **Citation analysis:** Monitoring which articles get mentioned, and in what context\\n- **Linkless mention tracking:** Surfacing brand or product references that LLMs pull without linking\\n- **Competitive prompt mapping:** Understanding where your content sits next to competitors inside AI outputs\\n\\nYour job doesn\u2019t stop with analysis, however. Many visibility specialists are starting to use automation tools, such as n8n, to simulate prompts. They also scrape LLM-generated results and run citation reports across tools like ChatGPT.\\n\\n## A Role Built on Writing, But Not Limited by It\\nMake no mistake, you must still focus on content writing. But it\u2019s writing with a system design behind it. It\u2019s built on a mix of skills: part strategist, part writer, part light technologist. Beyond trying to rank on Google, you\u2019re also trying to be the answer inside an LLM.\\n\\nIn reality, no one\u2019s hiring explicitly for \u201cLLM Visibility Specialists\u201d yet. But if you understand how content gets cited by AI tools, and you know how to structure, test, and refine what you publish, you\u2019re already doing the job.\\n\\nIf you\u2019re a writer who likes understanding how to track content performance and build repeatable frameworks, this role might be for you."},{"id":"/6-17-2025-clearscope-tool-progress","metadata":{"permalink":"/blog/6-17-2025-clearscope-tool-progress","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-17-2025-clearscope-tool-progress.md","source":"@site/blog/6-17-2025-clearscope-tool-progress.md","title":"ChatGPT evaluates my Clearscope-style tool","description":"So my Clearscope-style tool is workable. I almost had a meltdown from coding frustration but pulled myself together and got it done. Still, its time to compare my original goals with how well it performs now. So I compared my main.py code page with goals and asked ChatGPT for an evaluation.","date":"2025-06-17T00:00:00.000Z","tags":[],"readingTime":1.73,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"ChatGPT evaluates my Clearscope-style tool","date":"2025-06-17T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"The Emergence of the LLM Visibility Specialist","permalink":"/blog/6-17-2025-The LLM-visibility-expert"},"nextItem":{"title":"How to Optimize Your SEO Funnel","permalink":"/blog/6-16-2025-optimize-your-seo-funnel"}},"content":"So my Clearscope-style tool is workable. I almost had a meltdown from coding frustration but pulled myself together and got it done. Still, its time to compare my original goals with how well it performs now. So I compared my main.py code page with goals and asked ChatGPT for an evaluation.\\n\\n<img src=\\"/img/recap.png\\" alt=\\"Select Sheet\\" width=\\"800\\"/>\\n\\n\x3c!--truncate--\x3e\\n\\nThe primary features are satisfied, but I can still add more:\\n\\n<img src=\\"/img/enhance.png\\" alt=\\"Select Sheet\\" width=\\"800\\"/>\\n\\nSome of these features are just nice to have. I asked ChatGPT \\"Which of the missing features would be most valuable to a content writer?\\" and why\\n\\n## My Top Missing Feature\\nChatGPT asserts I should include \\"Cross-Article Theme and Subtopic Aggregation\\" within the app. The reasoning is that....\\n\\n\\"Writers don\u2019t just want to know what each individual article says, they want a synthesized overview that answers\\":\\n\\n- \u201cWhat are the recurring angles everyone\u2019s covering?\u201d\\n- \u201cWhat terms or entities are showing up the most?\u201d\\n- \u201cWhich subtopics or FAQs should I definitely include to stay competitive?\u201d\\nit\'s true, answering these questions would help make my article more comprehensive but differentiated.\\n\\nIn short order, it would...\\n\\n- Automatically extract all subtopics and questions from the summaries.\\n- Count frequency and group similar terms.\\n- Display a ranked list of the most mentioned themes, subtopics, and questions across all top-ranking articles.\\n\\nFor now, I\'m only requesting 10 summaries at a time. I could easily increase that number, but costs are involved.\\n\\n### Stating the benefits explicitly\\nChatGPT notes that, rather than having to read through each summary and manually deduce trends, this feature would basically produce a prioritized content map instead.\\n\\nAnd that would save me time, help avoid content gaps, and increase my chances of outperforming competitors in terms of search page results.\\n\\n### Bonus features I should consider\\nAdditionally, I could highlight frequently mentioned topics (core expectations) and rarely mentioned but important (opportunities to stand out)\\n\\nThis would help a writer decide what to match and where to differentiate, the same kind of information that Clearscope and MarketMuse sell for a premium."},{"id":"/6-16-2025-optimize-your-seo-funnel","metadata":{"permalink":"/blog/6-16-2025-optimize-your-seo-funnel","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-16-2025-optimize-your-seo-funnel.md","source":"@site/blog/6-16-2025-optimize-your-seo-funnel.md","title":"How to Optimize Your SEO Funnel","description":"Turn your SEO strategy into a growth engine","date":"2025-06-16T00:00:00.000Z","tags":[],"readingTime":2.24,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"How to Optimize Your SEO Funnel","date":"2025-06-16T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"ChatGPT evaluates my Clearscope-style tool","permalink":"/blog/6-17-2025-clearscope-tool-progress"},"nextItem":{"title":"What Is An SEO Funnel?","permalink":"/blog/6-15-2025-what-is-an-seo-funnel"}},"content":"## Turn your SEO strategy into a growth engine\\nYou want to be strategic when it comes to planning content. If you\'re serious about promoting growth, here\'s a smart framework to use:\\n\\n### Begin with BOFU\\nDo not divert your attention from bottom of funnel pages until they rank and convert. They are the ones that directly drive sales.\\n\\nWIth BOFU content, make sure you:\\n- Target the most high intent keywords\\n- Check that your site has fast load times\\n- Your site is fully functional on all devices\\n- Optimize your headers and meta descriptions\\n- Present compelling calls to action\\n\\n\x3c!--truncate--\x3e\\n\\n### Populate the Funnel with MOFU Content\\nWith your BOFU content set up, it\u2019s time to work on the middle of the funnel.\\n\\nYour prospective customers still have questions, and they need to know more before they\u2019re ready to buy. So the onus is on you to answer those questions.\\n\\nHigh converting blog posts and comparison pages are the best way to achieve this.\\n\\nTo fill your funnel with MOFU content, focus on these key areas:\\n- Make sure your internal links are easy to follow and your site data is well-organized\\n- Employ keyword groups that reflect purchase research\\n- Publish six new pieces of mid-funnel content each month\\n\\n### Long Term Authority Content\\nIf you aren\u2019t an enterprise brand or working to build topical authority over a long period, there\u2019s no need to invest heavily in TOFU (top of funnel) content. Its not worth your time.\\n\\nInstead, focuse on educational content that is helpful and not filler.\\n\\n## Technical SEO Still Matters\\nIf your site\u2019s technical foundation is weak, great content won\u2019t perform.\\n\\nDirect to consumer brands should be careful to:\\n- Fix broken links and indexation issues\\n- Audit site speed and mobile performance\\n- Review headers and meta tags\\n- Clean up orphan pages and crawl waste\\n\\n### The Right Ways to Build Links\\nOnce your funnel content is in place, amplify it with real backlinks by:\\n\\n- Manual outreach, not link farms\\n- Relationship building with relevant publishers\\n- Earning links to your BOFU and MOFU pages\\n\\nBacklinks not only improve authority, they signal relevance to Google and push your funnel content higher in the rankings.\\n\\n## Last Words\\nDon\u2019t overcomplicate your SEO strategy. You won\'t be able to cover all your bases. But you can be ready when a prospective customer is ready to buy.\\nSo:\\n\\n- Build BOFU pages first\\n- Use MOFU content to feed demand\\n- Let bigger brands play with TOFU\\n- Optimize your site\u2019s technical health\\n- Earn links that matter\\n\\nFollows the points to turn your SEO funnel into a sales funnel."},{"id":"/6-15-2025-what-is-an-seo-funnel","metadata":{"permalink":"/blog/6-15-2025-what-is-an-seo-funnel","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-15-2025-what-is-an-seo-funnel.md","source":"@site/blog/6-15-2025-what-is-an-seo-funnel.md","title":"What Is An SEO Funnel?","description":"If you\'re producing content that is not seeing results, the problem might not be your writing. It could be your funnel.","date":"2025-06-15T00:00:00.000Z","tags":[],"readingTime":2.69,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"What Is An SEO Funnel?","date":"2025-06-15T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How to Optimize Your SEO Funnel","permalink":"/blog/6-16-2025-optimize-your-seo-funnel"},"nextItem":{"title":"Posting on Reddit Just Became a Lot More Valuable","permalink":"/blog/6-14-2025-OpenAI-makes-Reddit-posting-worthwhile"}},"content":"If you\'re producing content that is not seeing results, the problem might not be your writing. It could be your funnel.\\n\\nAn SEO funnel is a framework that helps guide potential customers from the awareness stage to the conversion stage through organic search. It is similar to a traditional marketing funnel but specifically tailored for search engine optimization.\\n\\nUnderstanding how to target content at each stage of an SEO funnel can be the difference between a blog that merely ranks and one that drives conversions.\\n\\nLet\'s break down this funnel and see how you can make it work for your business.\\n\\n\x3c!--truncate--\x3e\\n\\n## What Is an SEO Funnel?\\nThe SEO funnel reflects the buyer\'s journey, segmenting searcher intent into three main stages: TOFU, MOFU, and BOFU.\\n\\nEach stage has distinct objectives, content forms, and keyword focuses.\\n\\n### TOFU: Top of Funnel\\nAt the product awareness level, potential buyers are just beginning to understand a subject. They are not in a purchasing mindset, they\'re in simply trying to understand the product.\\n\\nContent writers should focus on building trust and authority with this content.\\n\\nBut... TOFU content is frequently susceptible to Google\'s AI Overviews and generative search features. In other words, content at this stage is becomeing harder to drive traffic to.\\n\\nA prime example would be a blog post titled \\"What is a drip email campaign?\\"\\n\\nAnother might be \\"How does cloud storage work?\\"\\n\\nTOFU content still has a role, but that role is more akin to long term brand building or establishing SEO authority. It does not convert directly.\\n\\n### MOFU: Middle of Funnel\\nThe middle of the funnel is where prospects do their research. Potential buyers are in the final stages of the decision making process. Here, the potentialbuyer has narrowed their choices and just need a bit more information to push them over the line.\\n\\nThe best content for this stage is comparison pieces (e.g., \\"[Brand A] vs. [Brand B]\\"), listicles (e.g., \\"Best Data Pipeline Tools for 2025\\"), and guides (e.g., \\"How to Choose the Right Direct Mail Strategy\\").\\n\\nMOFU keywords that drive high quality, purchase intent traffic to your site are often found in blog posts and collection pages.\\n\\nExamples:\\n\\n- \u201cNotion vs. Trello: Which Is Better for Remote Teams?\u201d\\n- \u201cBest Project Management Tools for Freelancers\u201d\\n- \u201cHow to Choose the Right Email Marketing Platform\u201d\\n\\nThese keywords tend to fall into a few predictable categories:\\n\\n- \\"alternative\\" searches (e.g., \\"Mailchimp alternative\\")\\n- \\"vs.\\" searches (e.g., \\"Dropbox vs. Google Drive\\")\\n- \\"best\\" searches (e.g., \\"Best CRM software for startups\\")\\n\\nRanking for these terms can have a direct impact on your conversion rate.\\n\\n### BOFU: Bottom of Funnel\\nIf you are not focusing on bottom of funnel (BOFU) keywords, you are missing out on easy money.\\n\\nAt this stage, people are ready to buy\u2014they just need to find the right provider. These are high-intent queries with the clearest path to conversion.\\n\\nExamples include:\\n\\n- \u201cFreelance project manager for hire NYC\u201d\\n- \u201cEmail automation software for ecommerce\u201d\\n- \u201cBuy cloud storage with unlimited bandwidth\u201d\\n\\nBOFU content typically lives on product, service, or landing pages. These pages should be clear, conversion-optimized, and filled with proof points.\\n\\nIf you\'re not targeting BOFU terms, you\'re leaving revenue on the table."},{"id":"/6-14-2025-OpenAI-makes-Reddit-posting-worthwhile","metadata":{"permalink":"/blog/6-14-2025-OpenAI-makes-Reddit-posting-worthwhile","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-14-2025-OpenAI-makes-Reddit-posting-worthwhile.md","source":"@site/blog/6-14-2025-OpenAI-makes-Reddit-posting-worthwhile.md","title":"Posting on Reddit Just Became a Lot More Valuable","description":"Reddit appears to be evolving from a simple discussion platform to influential content resource for ChatGPT.","date":"2025-06-14T00:00:00.000Z","tags":[],"readingTime":1.28,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Posting on Reddit Just Became a Lot More Valuable","date":"2025-06-14T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"What Is An SEO Funnel?","permalink":"/blog/6-15-2025-what-is-an-seo-funnel"},"nextItem":{"title":"The Limits of OpenAI","permalink":"/blog/6-13-2025-limits-of-openai"}},"content":"Reddit appears to be evolving from a simple discussion platform to influential content resource for ChatGPT.\\n\\nThat\'s not conjecture. OpenAI\'s recent partnership with Reddit has triggered a sharp rise in Reddit citations by ChatGPT. They\'re up an astounding 436% over the past month.\\n\\n\x3c!--truncate--\x3e\\n\\n## Is Reddit really ChatGPT\'s BFF?\\nCurrently, rougnly 5.9% of all citations in ChatGPT\'s responses come from Reddit, making it the second most referenced domain after Wikipedia. The percentage is quite a leap considering how long other platforms have been part of ChatGPT\'s content base.\\n\\nWhile Perplexity and Google\'s AI Overviews (GAIO) still draw content from Reddit, they have not experienced this same kind of growth in being referenced or cited as sources. It appears this new focus on Reddit is exclusive to ChatGPT.\\n\\nThe change implies internal changes at OpenAI in how it manages retrieval augmented generation (RAG) and resource prioritization. For those working in content marketing and SEO, this means Reddit has become a much more valuable property. Don\'t neglect it!\\n\\n## The Bottom Line\\nA tactic that once helped brands surface in Perplexity has now been pulled into a much larger arena\u2014where ChatGPT leads the show. All of which means: If your brand or product shows up in Reddit threads, it\u2019s far more likely to show up in ChatGPT results.\\n\\nFor companies that care - and they should - this shift offers new avenue to expand their reach. Beyond brand awareness, it\u2019s a fresh reason to engage in Reddit conversations, and a strong incentive to make those contributions informative."},{"id":"/6-13-2025-limits-of-openai","metadata":{"permalink":"/blog/6-13-2025-limits-of-openai","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-13-2025-limits-of-openai.md","source":"@site/blog/6-13-2025-limits-of-openai.md","title":"The Limits of OpenAI","description":"Constructing a custom content brief generator is an exciting endeavor. If done right, you can end up with a Clearscope-style tool that analyzes and summarizes the main topics from top-ranking search results. But testing your tool can also test your patience.","date":"2025-06-13T00:00:00.000Z","tags":[],"readingTime":2.79,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"The Limits of OpenAI","date":"2025-06-13T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Posting on Reddit Just Became a Lot More Valuable","permalink":"/blog/6-14-2025-OpenAI-makes-Reddit-posting-worthwhile"},"nextItem":{"title":"Insights on How to Make SEO Work For You","permalink":"/blog/6-12-2025-make-seo-work for you"}},"content":"Constructing a custom content brief generator is an exciting endeavor. If done right, you can end up with a Clearscope-style tool that analyzes and summarizes the main topics from top-ranking search results. But testing your tool can also test your patience.\\n\\nSo when it came to choosing an LLM for this tool, I instinctively chose OpenAI. GPT 4 was a known quantity; it had the ecosystem and a simple API.\\n\\nAfter some testing, however, I realized OpenAI was coming up short, especially when it came to flexibility, speed, and trial experience. That\u2019s when I moved to Gemini 1.5.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why I switched: short version\\nOpenAI\'s developer API is impressive on paper. It gives you access to powerful LLM models like GPT 4 and GPT 3.5. But using these models at even small scale with their free tier left me coming up short. And I was only focused on testing.\\n\\nRate limits kicked in almost immediately. For a tool intended to analyze several URLs one after the other, having to wait or retry because of usage caps really bogged the entire process down. Even after switching from GPT 4 to GPT 3.5, I still ran into constraints.\\n\\nBefore considering their upgrade, I wanted to see what my alternativew were.\\n\\n## A quick look at alternatives\\nIn my search, Anthropic\'s Claude was tempting, especially when it comes to tasks needing context. But its pricing was confusing and its access was limited.\\n\\nGrok was fast and open, but not quite ready for production without extra work. I needed a solution that offered managed APIs rather than one that caused additional issues.\\n\\n## Gemini 1.5: Faster and Cheaper\\nGoogle\'s Gemini API was not an obvious first pick. It was hard to discern what product would be best for me: Studio, Pro, Flash, AI Platform. I actually had to perform AI analysis to help me decide.\\n\\nBut once I\'d figured out how to integrate Gemini 1.5 Flash into my application, I noticed an immediate improvement in speed.\\n\\nWhat really clinched the deal was Google Cloud\'s $300 free trial. It\'s generous enough to allow for extensive testing. The trial is linked to a billing account, so users have to be mindful not to exceed the free tier. But once the trial is activated, the user has full access to the Gemini API.\\n\\nI have being a big fan of corporate behemoths, but Google deserves accolades here.\\n\\nThe Gemini 1.5 flash model, which I\'m employing for text summarization tasks, is efficient and accurate. It\'s also fine tuned to handle repetitive tasks, which is perfect for generating briefs in a Clearscope-style manner.\\n\\n## Not entirely free, but worth the cost\\nIt\'s true - neither OpenAI nor Gemini really offer a usable free tier for production. But Gemini\'s paid tiers are reasonably priced, especially if you are able to use the 1.5 flash model instead of the more expensive 1.5 pro version.\\n\\n## Last words\\nLooking back, starting with OpenAI was a good move. For a content analysis tool that must retrieve and analyze several URLs, Gemini 1.5 Flash came through where OpenAI couldn\u2019t: with speed, reliability, and cost effectiveness.\\n\\nI\'ll still use OpenAI for other purposes. In this instance, Gemini came out head. If you\u2019re creating something comparable and feel constrained by OpenAI\u2019s capabilities, give Gemini a shot. Its $300 trial goes a long way."},{"id":"/6-12-2025-make-seo-work for you","metadata":{"permalink":"/blog/6-12-2025-make-seo-work for you","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-12-2025-make-seo-work for you.md","source":"@site/blog/6-12-2025-make-seo-work for you.md","title":"Insights on How to Make SEO Work For You","description":"Ranking in Google search is no longer the only game in town, which means your content strategy is ripe for change. If you want to become visible with Google\'s AI Answer Engine, you\'ll need your content to follow an answer structure.","date":"2025-06-12T00:00:00.000Z","tags":[],"readingTime":2.635,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Insights on How to Make SEO Work For You","date":"2025-06-12T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"The Limits of OpenAI","permalink":"/blog/6-13-2025-limits-of-openai"},"nextItem":{"title":"Why Crystal Knows Is a Secret Weapon for Lead Generation","permalink":"/blog/6-11-2025-crystal-knows-for-leads.md"}},"content":"Ranking in Google search is no longer the only game in town, which means your content strategy is ripe for change. If you want to become visible with Google\'s AI Answer Engine, you\'ll need your content to follow an answer structure.\\n\\nContent structure matters more than repetition when it comes to Google. For instance, directly answering a question in a clear manner makes content far more likely to be cited by AI engines.\\n\\nUsing phrases such as \\"According to [your brand]...\\" works especially well because they imitate the structure of reliable sources. The key here is to sound authoritative. The AI does not favor filler; it favors straightforwardness.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why context-rich pages beat dispersed content\\n\\nPreviously, the idea was to distribute related concepts over several brief pages, as this would be beneficial for keyword ranking. However, this approach dilutes your authority.\\n\\nIf you combined these fragmented pages into fewer comprehensive ones, you would experience more AI citations. That\'s because AI models favor pulling from context rich sources. Additionally, combining related subjects on one page also makes for better reference and improves search outcomes.\\n\\n## Transparency: More important than you think\\nBeing transparent is also important, like explaining your methods, listing your data sources, and even noting your work\'s limitations.\\n\\nWith AI, the goal of search engines is highlight content that seems trustworthy and can be easily checked. So adding a straightforward \\"How we calculated this\\" section to your content is a smart way to promote your transparency, especially for AI tools looking to cite online information.\\n\\n## Write the way you talk to get noticed\\nAdjusting the tone of your writing will also help. Instead of corporate speak like \\"Best practices for...,\\" you might want to use phrasing that\'s closer to everyday speech: \\"What is the best way to...\\"\\n\\nText that is more conversational in style aligns better with the training data that most LLMs employ. Real world dialogue is key here, since using more natural sounding questions increases your content\'s chances of being cited. Even small language adjustments can give you the upper-hand here.\\n\\n## Fresh data is growing in importance\\nWhile evergreen content still holds value, AI desires fresh content more. Be sure to update key stats and insights monthly if relevant. You\'ll gain additional citations. Note too that AI tools favor the most current information to remain relevant.\\n\\n## For B2B companies, an AI strategy is no longer optional\\nIf you\'re focused on the B2B market, the decision-makers you\'re shorting for are using AI not Google. SEO is not dead but it is sharing the spotlight. Which means you ned to structure your content so that AI is able to read and cite it.Embracing this strategy can help increase your leads and conversion rate.\\n\\n## Next steps for forward thinking companies\\nThe next step would be to audit every page of your site for readability. One wasy to streamline this is to construct a content architecture that prioritizes direct answer formats. Pretty soon, it won\'t be how well you rank in Google but how often you\'re mentioned in AI generated responses.\\n\\nBranding become intertwined with AI here, so be sure to act accordingly."},{"id":"/6-11-2025-crystal-knows-for-leads.md","metadata":{"permalink":"/blog/6-11-2025-crystal-knows-for-leads.md","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-11-2025-crystal-knows-for-leads.md.md","source":"@site/blog/6-11-2025-crystal-knows-for-leads.md.md","title":"Why Crystal Knows Is a Secret Weapon for Lead Generation","description":"Reaching out to cold leads can be a shot in the dark, but Crystal Knows makes it a lot less intimidating.","date":"2025-06-11T00:00:00.000Z","tags":[],"readingTime":1.855,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Why Crystal Knows Is a Secret Weapon for Lead Generation","date":"2025-06-11T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Insights on How to Make SEO Work For You","permalink":"/blog/6-12-2025-make-seo-work for you"},"nextItem":{"title":"Why I Like DataForSEO, Pt. 2","permalink":"/blog/6-10-2025-gunning-for-dataforseo"}},"content":"Reaching out to cold leads can be a shot in the dark, but <a href=\\"https://crystalknows.com\\">Crystal Knows</a> makes it a lot less intimidating.\\n\\nSome clever marketer figured out how to leverage public data, behavioral models, and AI to create a smart leads generation tool. It gives sales and marketing teams a psychological edge by providing them with the <a href=\\"https://www.discprofile.com/what-is-disc\\">DISC personality assessments</a> of their prospects.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why communication styles are so important\\nCrystal Knows is somewhat dependent on the client having taken a DISC assessment. If they have, the software can determine whether a lead prefers bullet points or detailed explanations, formal language or casual tone, quick decisions or thoughtful pacing. It\'s like getting an inside scoop on someone.\\n\\nBut this isn\u2019t just a nice-to-have, it\'s may make the difference between being ignored and being heard.\\n\\nIt\'s all based on a simple premise - you should tailor your emails, calls, and outreach strategies to match the communication style of your leads. It\'s another version of \'matching\', a tried and true in-person sales strategy.\\n\\nUnderstanding a potential customer is what  personalization is all about. It turns what might otherwise be a generic pitch into something much more meaningful.\\n\\n## My experience with using it on LinkedIn\\nI\'m hardly one to get too excited about marketing tools. But this one was actually fun to use.\\n\\nTo check it out, I used the software\'s Chrome extension to check out my LinkedIn profile. It gave me a pretty exhaustive about how best to communicate to ...me. And all through a thin side panel on the right side of the LI profile.\\n\\nThe only thing that kind of shook me was that I took the DISC assessment maybe a decade ago. And here it was being used for marketing purposes. Something tells me all this was in the fine print when I signed off on taking it.\\n\\nHere is what the full page view of DISC looks like in Crystal Knows:\\n\\n<img src=\\"/img/disc.png\\" width=\\"650\\" />\\n\\nIn addition to LinkedIn, Crystal Knows also integrates with Salesforce and Gmail, making it easy to write personalized messages where you\'re already working.\\n\\nTo get a feel for what the Crystal Knows offers, I recommend taking advantage of its free trial."},{"id":"/6-10-2025-gunning-for-dataforseo","metadata":{"permalink":"/blog/6-10-2025-gunning-for-dataforseo","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-10-2025-gunning-for-dataforseo.md","source":"@site/blog/6-10-2025-gunning-for-dataforseo.md","title":"Why I Like DataForSEO, Pt. 2","description":"If you are considering DataForSEO for content strategy or brief creation, I have insights to share. Here\'s what I found.","date":"2025-06-10T00:00:00.000Z","tags":[],"readingTime":2.655,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Why I Like DataForSEO, Pt. 2","date":"2025-06-10T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Why Crystal Knows Is a Secret Weapon for Lead Generation","permalink":"/blog/6-11-2025-crystal-knows-for-leads.md"},"nextItem":{"title":"DataForSeo, The Low-Cost SerpAPI alternative","permalink":"/blog/6-9-2025-data-for-seo"}},"content":"If you are considering DataForSEO for content strategy or brief creation, I have insights to share. Here\'s what I found.\\n\\n## DataForSEO handles search intent really well\\n\\nUnlike other tools that visualize intent with trees or bubbles, DataForSEO gives you the information straight. The data is raw, structured, and ready for automation. Their Keyword Data API v3 includes an intent field for every keyword.\\n\\nYou can immediately see whether a keyword is associated with informational, navigational, commercial, or transactional intent. There\'s is no guesswork and no decoding required.\\n\\n\x3c!--truncate--\x3e\\n\\nIf you are building something semi-automated like my content brief generator, this is what you need. You can filter keywords by intent, group them into clusters, and even change your prompts to GPT based on the different types of intents (for example: writing prompts for a product page versus a blog post).\\n\\n## Related keywords comes WIth clues too\\n\\nThe Related Keywords API provides long tail keywords, items like questions, modifiers, and SERP indicators (such as PAA boxes or featured snippets). You can sort through this content to build layers of intent, especially if you\'re trying to map out a full funnel.\\n\\nDon\'t dismiss this data as just more keywords. It\'s key to understanding how people think when they search.\\n\\n## SERP features are also covered\\nDataForSEO\u2019s SERP API displays whether a keyword brings up:\\n\\n- Featured snippets\\n- People Also Ask\\n- Shopping results\\n- Sitelinks\\n\\nSo you don\'t have to guess, and you can even spot patterns like:\\n\\n- \\"How to\\" plus a featured snippet often reveal strong informational intent\\n\\n- Product title + shopping results equal clear transactional intent\\n\\nIt\'s a smart way to match your content format to what Google already rewards.\\n\\n## Why DataForSEO works well my Clearscope-style analyzer\\nHere is where the rubber meets the road. The info I get from DataForSEO complements what my Clearscope-style analyzer does.\\n\\nIf you take a closer look, you\'ll see that DataForSEO is great for:\\n\\n- Mapping out keyword intent\\n- Viewing SERP structure\\n- Scoring keywords by volume, CPC, difficulty\\n\\nSure, DataForSEO doesn\u2019t tell me how to structure your page. But that\u2019s where my Clearscope-style tool will comes in. It analyzies how the top content perform, which keywords they\u2019re using, how the page is laid out.\\n\\nPutting these two tools together gives me a good look at what to write about and why. It tells me how to write the content so it\'s able to compete in search.\\n\\n## My gains from merging the two\\n\\nConnecting these two tools help me create:\\n\\n- **Smarter briefs:** I\'m able to pre-load SERP features, keyword intent, and even CPC info into my outlines.\\n\\n- **Quicker workflowsL** Depending on the keyword clusters, I\'m able to auto-trigger outline types for my briefs.\\n\\n- **Better topic prioritization:** Keyword gaps are not the end-all when it comes to selecting topics. Together, these tools help me rank potential topics based on intent + volume + keyword difficulty.\\n\\nIn the end, this combo helps me move away from simply \\"here\u2019s a keyword\\" to \\"here\u2019s a well-structured brief for the right type of content\\". And it does so without having to perform manual sorting. Which is a huge timesaver."},{"id":"/6-9-2025-data-for-seo","metadata":{"permalink":"/blog/6-9-2025-data-for-seo","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-9-2025-data-for-seo.md","source":"@site/blog/6-9-2025-data-for-seo.md","title":"DataForSeo, The Low-Cost SerpAPI alternative","description":"Yesterday, I spent most of the afternoon sorting through API tools for use in my semi-automated SEO system. I need one that can feed select data into the custom Clearscope-style tool I\u2019m building. The goal is to analyze top-ranking pages and generate detailed content briefs.","date":"2025-06-09T00:00:00.000Z","tags":[],"readingTime":3.085,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"DataForSeo, The Low-Cost SerpAPI alternative","date":"2025-06-09T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Why I Like DataForSEO, Pt. 2","permalink":"/blog/6-10-2025-gunning-for-dataforseo"},"nextItem":{"title":"MarketMuse is Awesome; I Won\'t Be Using It","permalink":"/blog/6-8-2025-moving-on-from-marketmuse"}},"content":"Yesterday, I spent most of the afternoon sorting through API tools for use in my semi-automated SEO system. I need one that can feed select data into the custom Clearscope-style tool I\u2019m building. The goal is to analyze top-ranking pages and generate detailed content briefs.\\n\\nChatGPT was helpful in narrowing down what factors to consider, but I was still let with plenty of options to pursue. In the end analysis, price was again a  major factor.\\n\\n\x3c!--truncate--\x3e\\n\\nI had my heart set on <a href=\\"https://SerpAPI.com\\">SerpAPI</a>, but their free version isn\u2019t allowed for commercial use. That\'s fair, but without steady SEO client income, it\'s also a heavy lift. Trying to find a workaround felt pointless and kind of lame. So I started looking elsewhere.\\n\\n## My brief flirtation with Zenserp\\n\\nThe next SEO-related API tool I came across was <a href=\\"https://zenserp.com\\">Zenserp</a>. Their startup plan runs $23/month for up to 5,000 searches and includes solid NLP-based topic clustering. Not bad. Other tools like Serper, SearchAPI, and ValueSearch also crossed my path. But DataForSEO kept showing up on several recommendation lists, so I decided to take a closer look.\\n\\n## An Alternative With A Big Plus on Pricing\\n\\n<a href=\\"https://dataforseo.com\\">DataForSEO</a> is even more competitive on price ($0.0006 per SERP page). In an effort to compare with Zenserp, I asked ChatGPT to multiply 5000 x $0.0006 per SERP page result. The answer: $3, quite a discount from $23.\\n\\n\\"What\'s the catch?\\" I asked ChatGPT. Apparently, DataForSEO is \\"for developers\\" and not quite as user-friendly. But being a newly-minted \\"vibe-coder\\", I know I can handle that.\\n\\nChatGPT notes that \\"Zenserp has a simpler setup and often includes structured extras like local pack and knowledge panel data\\", whereas \\"DataForSEO is more customizable, often preferred by developers building at scale\u2014but it may require more setup work, including batch processing and parsing.\\"\\n\\n## Comprehensive Data!\\n\\nDataForSEO goes full throttle on providing data. Below is a full list of the SERP elements it provides stuctured data for:\\n\\n- **Organic Results**: Standard search listings with titles, URLs, and descriptions.\\n- **Paid Advertisements**: Google Ads data, including ad titles and URLs.\\n- **Featured Snippets**: Highlighted answers appearing at the top of search results.\\n- **Knowledge Panels**: Information boxes summarizing topics.\\n- **Local Packs**: Listings of local businesses with relevant details.\\n- **Image and Video Results**: Multimedia content related to the search query.\\n- **News Results**: Recent articles and headlines.\\n- **Shopping Results**: Product listings with prices and seller information.\\n- **Answer Boxes**: Direct answers to specific queries.\\n- **People Also Ask**: Related questions that users commonly search for.\\n- **Related Searches**: Suggestions for similar searc\\n\\nDataForSEO also provides additional APIs for backlinks, keywords, and on-page data.\\n\\n### API Modules Include\\n- Google SERP API (top 100 results for any keyword)\\n- Keyword Data API (volume, CPC, difficulty)\\n- On-Page API (crawl and analyze site structure/content)\\n- Rank Tracking API (track positions over time)\\n- Labs API (includes NLP-powered features like keyword clustering and content ideas)\\n\\nI\'m comfortable working with APIs and parsing JSON, and since I\'m building my own GPT-based content brief generator, it\'s a perfect fit.\\n\\n## Not Everything Is A Box of Chocolates\\n\\nI had planned to use <a href=\\"https://AlsoAsked.com\\">AlsoAsked</a> to provide me with layed search intent. But again, people want to get paid for their products! (SMH).\\n\\nI\'m going to try approximate this with DataForSEO bur it won\'t be easy. I\'ll have to:\\n- Pull related questions and long-tail keywords\\n- Use the intent labels and modifiers (\\"how,\\" \\"best,\\" \\"vs,\\" etc.)\\n- Build my own tree/cluster structure (e.g., using GPT)\\n- Write logic or use GPT prompting to group those into \\"awareness \u2192 consideration \u2192 decision\\" stages\u2014or feed it into a visualizer. ughh\\n**we\'ll see.**"},{"id":"/6-8-2025-moving-on-from-marketmuse","metadata":{"permalink":"/blog/6-8-2025-moving-on-from-marketmuse","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-8-2025-moving-on-from-marketmuse.md","source":"@site/blog/6-8-2025-moving-on-from-marketmuse.md","title":"MarketMuse is Awesome; I Won\'t Be Using It","description":"MarketMuse is great for larger teams that are serious about content planning. I\'ve been enamored of its features. But to get a full picture, I need to review all aspects of this SEO tool.","date":"2025-06-08T00:00:00.000Z","tags":[],"readingTime":1.81,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"MarketMuse is Awesome; I Won\'t Be Using It","date":"2025-06-08T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"DataForSeo, The Low-Cost SerpAPI alternative","permalink":"/blog/6-9-2025-data-for-seo"},"nextItem":{"title":"When Everyone Has An n8n Agent","permalink":"/blog/6-7-2025-when-everyone-has-an-n8n-agent"}},"content":"<a href=\\"https://marketmuse.com\\">MarketMuse</a> is great for larger teams that are serious about content planning. I\'ve been enamored of its features. But to get a full picture, I need to review all aspects of this SEO tool.\\n\\n\x3c!--truncate--\x3e\\n\\n## +1: Content Clustering\\n\\nMarketMuse reveals which topics are worthwhile to cover and clues people in on keyword ranking difficulty and website\'s \'content authority level\'.\\n\\nIt also generates intelligent content plans filled with related topics and keywords. So it helps users think in terms of clusters of content rather than just individual posts.\\n\\n## +1: Search Intent Comparison\\n\\nA big draw of MarketMuse is that it evaluates planned content against search intent. Basically, it grades you on how well a future piece of content will serve its potential audience. In other words, it serves as a powerful nudge toward writing truly useful articles that perform well in search engine results.\\n\\n## +1: Content Monitoring\\n\\nAdditionally, MarketMuse monitors how well existing content is performing and alerts users when something needs fixing. While it also integrates with ChatGPT for writing assistance (this should be standard), it also analyzes how topics interrelate throughout your content.\\n\\nSo MarketMause provides a lot of useful insights. They even hav a MarketMuse Academcy (I LOVE this). But I won\'t be using it. A big number just jumped out as me. Should of checked first. Change of plans!\\n\\n## -3: Pricing\\n\\nAs a solopreneur, its foolhardy to disregard pricing. Even low-cost tools are a danger if you\'re indiscriminate about how many tools you\'re paying for. Don\'t leave yourself open to large bill at the end of the month.\\n\\nWith MarketMuse, we\'re talking $199/month to be on their basic plan. For additional features, this number jumps to $499/month. That\'s not a problem if you\'re a large corporation. I\'m not.\\n\\nEven Frase ($114/month to get API) is priced too high for me. Since I\'m a writer and not a full-fledged SEO agency, it looks like I might be going for <a href=\\"https://dataforseo.com/\\">DataForSEO</a>. I\'ll trade my convenience (its somewhat of a developer tool) for avoiding high monthly bills.\\n\\nSure, MarketMuse would be nice. But its not for me. I appreciate there\'s something for everyone in this marketplace."},{"id":"/6-7-2025-when-everyone-has-an-n8n-agent","metadata":{"permalink":"/blog/6-7-2025-when-everyone-has-an-n8n-agent","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-7-2025-when-everyone-has-an-n8n-agent.md","source":"@site/blog/6-7-2025-when-everyone-has-an-n8n-agent.md","title":"When Everyone Has An n8n Agent","description":"Personal AI agents are small software companions that operate quietly in the background to manage your business. They can manage your schedule and generally optimize your life. They\u2019re also about to go mainstream.","date":"2025-06-07T00:00:00.000Z","tags":[],"readingTime":4.195,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"When Everyone Has An n8n Agent","date":"2025-06-07T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"MarketMuse is Awesome; I Won\'t Be Using It","permalink":"/blog/6-8-2025-moving-on-from-marketmuse"},"nextItem":{"title":"How to Use GPT-4o\u2019s Vision Capabilities for CRO","permalink":"/blog/6-6-2025-use-GPT4o-vision-capabilities"}},"content":"Personal AI agents are small software companions that operate quietly in the background to manage your business. They can manage your schedule and generally optimize your life. They\u2019re also about to go mainstream.\\n\\nAI tools like [n8n](https://n8n.io/) connect APIs and triggers in a drag and drop fashion and work with LLM models like GPT-4o. Which means you can understand just about anything you throw at them. The future is not some far-off vision, it\'s present reality. The big question is what happens when everyone has one of these little helpers. How will people use them to get ahead?\\n\\nLet\'s review what the present reality looks like and where it might go from here.\\n\\n\x3c!--truncate--\x3e\\n\\n## It\u2019s Not All Trading Bots\\n\\nMany AI fans view trading bots as the prime use case for GPT-powered agents. One could imagine them scanning Twitter, Reddit, and market signals to auto-execute trades faster than any human could react. Some AI power users are undoubtedly pursuing this path. But it\u2019s not where most people will end up.\\n\\nThe bulk of AI agents won\u2019t be seeking stock market supremacy, or even crypto like [$FET](https://fetch.ai/). Chances are they\'ll be focusing on the far less glamorous task of optimizing workflow and output. Think content, outreach, lead generation, and solo entrepreneurship.\\n\\n## The Agents People Will Actually Use\\nHere are four categories of AI agents that will likely become common:\\n\\n### Micro-Entrepreneur Agents\\nThese agents autonomously create content and run simple businesses. They\'ll manage affiliate blogs, auto-publish posts, and even handle basic A/B testing for landing pages. The human \\"owner\\" of these operations simply supervises and adjusts as necessary.\\n\\n### Content Creator Agents\\nThink next level writing assistants we\'ve been anticipating. They\'ll generate articles, stories, and even books with minimal input from a human supervisor. They\'ll perform the basic functions of a newsroom staff for niche publications; they\'ll ghostwrite for bloggers and thought leaders.\\n\\n### Research and Personal Efficiency Agents\\nIf you need to stay current with legislation, these agents will get the job done. They\u2019ll analyze a large volume of reviews for sentiment or monitor price changes on an Amazon product. They might pull job listings, filter them according to your values, and apply for selet jobs with a personalized cover letter (note: it\u2019s already happening).\\n\\n### Outbound and Lead Gen Agents\\nOne of the most obvious applications here is running smart, GPT personalized outreach campaigns. These agents will handle lead scraping and enrichment, summarize recent social content for a target, and send custom messages based on real context.\\n\\nToday, these tasks are being accomplished by humans in relatively small numbers. They\u2019re not yet happening at scale for two reasons: The first is that we simply don\u2019t have enough of the right people to do these tasks at scale. The second is that we\u2019re still working out some issues with the agents themselves.\\n\\n## How People Will Generate Income From AI Agents\\nYou won\u2019t be selling the agent, you\u2019ll be selling the results it creates.\\n\\nHere\u2019s how this might break down:\\n\\n- **Creators** use agents to produce content and monetize through ads, affiliate deals, newsletters, or info products.\\n\\n- **Freelancers** use agents to increase output, take on more clients, or justify higher rates.\\n\\n- **Operators** build niche tools or services that are essentially wrappers around agents, such as outreach-as-a-service or SEO-as-a-service.\\n\\n- **Toolmakers** create reusable workflows, then sell those workflows or host them on marketplaces.\\n\\nIt may be like SaaS, but you don\u2019t need to hire a team or raise capital. You\u2019ll build an agent once and deploy it.\\n\\n## What This Might Look In Practical Terms\\nFast forward six months. You log in, and your n8n dashboard shows:\\n\\n- A content agent that generated three new SEO briefs overnight.\\n\\n- A lead gen agent that pulled 25 prospects and sent 12 messages, two of which replied.\\n\\n- A report agent that flagged a broken funnel in your analytics dashboard.\\n\\n- A distribution agent queued up three tweets, one newsletter introduction, and a cold pitch for a brand collaboration.\\n\\nYou didn\u2019t do any of this manually. You just built the system once. Now you\'ll be maintaining, prompting, and steering it.\\n\\n## The Real Competitive Edge\\nWhen everyone has agents, having one won\u2019t give you an edge anymore. It will just set the bar higher (people seem to forget this truism whenever a new innovation shows up). What matters is how well-trained, precisely scoped, and creatively applied your agent is. There will be differences.\\n\\nAnyone can connect OpenAI to a Google Sheet. But not everyone will:\\n- Prompt in a way that mimics top-tier strategists\\n- Extract insights that others miss\\n- Build a feedback loop that adapts to performance\\n- That\u2019s where the new leverage will be.\\n\\n## Final Thought\\n\\nIn the near future, your AI agent might not be trying to beat the market.It\u2019ll just be out there working. In other words, researching, writing, messaging, testing, and reporting while you sleep or have coffee. But if you build one right now, you\u2019ll have a serious head start."},{"id":"/6-6-2025-use-GPT4o-vision-capabilities","metadata":{"permalink":"/blog/6-6-2025-use-GPT4o-vision-capabilities","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-6-2025-use-GPT4o-vision-capabilities.md","source":"@site/blog/6-6-2025-use-GPT4o-vision-capabilities.md","title":"How to Use GPT-4o\u2019s Vision Capabilities for CRO","description":"If you\'re working on conversion rate optimization for a website, there\'s a new tool you\u2019ll want to start using: OpenAI\u2019s GPT-4o. Beyond interpreting visuals, it\'s also very sharp at identifying what\u2019s not working on a webpage and how to improve it.","date":"2025-06-06T00:00:00.000Z","tags":[],"readingTime":2.805,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"How to Use GPT-4o\u2019s Vision Capabilities for CRO","date":"2025-06-06T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"When Everyone Has An n8n Agent","permalink":"/blog/6-7-2025-when-everyone-has-an-n8n-agent"},"nextItem":{"title":"Link Building Without Breaking the Bank","permalink":"/blog/6-5-2025-link-building-without-breaking-bank"}},"content":"If you\'re working on conversion rate optimization for a website, there\'s a new tool you\u2019ll want to start using: OpenAI\u2019s GPT-4o. Beyond interpreting visuals, it\'s also very sharp at identifying what\u2019s not working on a webpage and how to improve it.\\n\\nThis article will show you how to leverage this technology for CRO. Using the guide below, you can run several CRO challenges across different B2B SaaS landing pages. It will deliver conversion-focused suggestions that are smart and actionable.\\nLet\'s begin.\\n\\n\x3c!--truncate--\x3e\\n\\n## Start with a Clear Expert Persona\\n\\nBefore asking 4o to analyze anything, define who it\'s pretending to be. You\u2019ll get helpful output if you start your prompt by assigning it a role. Stating \u201cconversion expert\u201d won\'t cut it, you\'ll need something more detailed.\\n\\nFor example, you could say:\\n\u201cYou are a senior CRO specialist with 10+ years of experience improving SaaS landing pages, particularly for startups targeting mid-market buyers. You understand user psychology, design best practices, and messaging frameworks like PAS and AIDA.\u201d\\n\\nThe more context you give, the more relevant the output will be.\\n\\n## Upload a Screenshot, Not a Link\\n\\nDon\u2019t paste in a URL and expect a quality output.\\n\\nInstead, upload a full-page screenshot. GPT-4o\u2019s Vision model is built to analyze visual layouts directly, and screenshots provide much clearer input than relying on a page fetch or rendering through a link.\\n\\n## Ask It to Describe the Page First\\n\\nBefore jumping into optimization suggestions, ask 4o to describe what it sees. You can include this as the first step of your prompt. This task....\\n\\n- Allows you to verify that it interprets the page correctly\\n- Actually improves the quality of its suggestions\\n\\nAnother smart tip is to ask it to describe everything it sees on the page from top to bottom before it offers suggestions. Sometimes you\'ll catch weird interpretation issues this way. It also gives the model a stronger starting point.\\n\\n## Give It Context Like You Would a Colleague\\nTo get genuinely helpful feedback, feed GPT-4o the background a strategist would need. Include:\\n\\n- What counts as a conversion (demo request? email sign-up?)\\n- Who the target audience is. Be specific. Are they decision-makers? DIY users?\\n- How people are landing on the page. Is it from ads, organic search, email?\\n- Any other context that influences messaging or structure.\\n\\nDon\'t hold back. The more grounded your prompt is in the real-life funnel, the better the suggestions will be.\\n\\n## Guide the Analysis\\nNow you\u2019re ready to ask for a full CRO teardown using its Vision capabilities. Remember to be specific:\\n\u201cUse your Vision features to analyze this screenshot and provide conversion-focused suggestions. Don\u2019t use Code Interpreter.\u201d\\n\\nYou can even direct it to focus on certain areas like CTA placement, headline clarity, hierarchy, or visual flow.\\n\\n## Last Tips Before Prompt\\nIf you want to really get the most from ChatGPT-4o:\\n\\n- Be precise about what you want from the model.\\n- Speak to it like you would a collaborator, provide motivation and context.\\n- Use clear language.\\n- Use natural language endings, even a thank you adds clarity\\n\\nGPT-4o is a valuable CRO tool you can add to your CRO process. While not a replacement for human insight, it can highlight issues, test ideas, and sharpen the details that matter. For a more in-depth view of its capabilities, check out https://www.v7labs.com/blog/chatgpt-with-vision-guide"},{"id":"/6-5-2025-link-building-without-breaking-bank","metadata":{"permalink":"/blog/6-5-2025-link-building-without-breaking-bank","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-5-2025-link-building-without-breaking-bank.md","source":"@site/blog/6-5-2025-link-building-without-breaking-bank.md","title":"Link Building Without Breaking the Bank","description":"Link building is one of those SEO topics many professionals prefer to avoid. It\u2019s less about analysis and insights and more about outreach. And for that, you need leads.","date":"2025-06-05T00:00:00.000Z","tags":[],"readingTime":1.74,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Link Building Without Breaking the Bank","date":"2025-06-05T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How to Use GPT-4o\u2019s Vision Capabilities for CRO","permalink":"/blog/6-6-2025-use-GPT4o-vision-capabilities"},"nextItem":{"title":"Why I Moved On from Surfer SEO (Mostly)","permalink":"/blog/6-4-2025-moving-on-from-surfer-seo"}},"content":"Link building is one of those SEO topics many professionals prefer to avoid. It\u2019s less about analysis and insights and more about outreach. And for that, you need leads.\\n\\nBut buying leads is expensive. Subscribing to tools like Postega or Respona can be even worse, running $99 to $199 per month. So what\u2019s a fledgling SEO pro to do? Connect a few solid tools together, of course.\\n\\nThe solution starts with [Hunter.io](https://hunter.io), a lightweight email outreach tool that supplements basic lead info. It also generates niche lead lists through dropdown filters. The next step is to connect it to google sheets and a gmass browser extension.\\n\\n\x3c!--truncate--\x3e\\n\\nHere\u2019s a short video that walks through Hunter.io basics.\\n\\n<iframe\\n  width=\\"560\\"\\n  height=\\"315\\"\\n  src=\\"https://www.youtube.com/embed/VkO5y9Zyhd8?si=2GtD1wlw9TlZsNEh\\"\\n  title=\\"YouTube video player\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\"\\n  referrerpolicy=\\"strict-origin-when-cross-origin\\"\\n  allowfullscreen\\n></iframe>\\n\\n\\nOnce you obtain the leads you want, you can download them as a CSV and upload the data to a Google Sheet.\\n\\nI haven\u2019t tried this yet, but you could probably build a lightweight MCP agent to fetch relevant personalization data. Advanced MCP setups can use AI to enrich leads and even generate content or campaign suggestions. For an ambitious example, check out [\u201cRevolutionizing Outbound Sales: Why I Built a Natural Language Lead Generation MCP Server\u201d](https://dev.to/bashirk/revolutionizing-outbound-sales-why-i-built-a-natural-language-lead-generation-mcp-server-1i7i).\\n\\nSome setups even use [Zapier MCP agents](https://zapier.com/mcp) and [Apify scrapers](https://apify.com/apify/web-scraper) to send lead data directly to HubSpot or other CRMs. But I digress.\\nHere is [another example](https://www.linkedin.com/posts/joshwhitfieldai_model-context-protocol-mcp-is-the-biggest-activity-7325489572904095744--U-x/)\\n\\nBack to my project: once I\u2019ve cleaned up the data in Google Sheets, I use the [GMass browser extension](https://www.gmass.co/) to run a mail merge campaign. It allows me to send personalized emails to everyone on my list, all at once, complete with merge fields for names, companies, and custom introductions. (See images below.).\\n\\nSelect your Google Sheets leads file using the extension:\\n<img src=\\"/img/gmass.png\\" alt=\\"Select Sheet\\" width=\\"350\\"/>\\n\\nConfigure settings before you send off your email. Run tests first.\\n<img src=\\"/img/sendtest.png\\" alt=\\"Send Test\\" width=\\"350\\"/>\\n\\n\\nThis setup is still pretty basic, but it saves me a ton of money. Once i start rolling, I\u2019ll probably add in MCP capabilities if they substantially help."},{"id":"/6-4-2025-moving-on-from-surfer-seo","metadata":{"permalink":"/blog/6-4-2025-moving-on-from-surfer-seo","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/6-4-2025-moving-on-from-surfer-seo.md","source":"@site/blog/6-4-2025-moving-on-from-surfer-seo.md","title":"Why I Moved On from Surfer SEO (Mostly)","description":"Not long ago, Surfer SEO emerged as a leading AI content tool, gaining momentum on ChatGPT. Unlike all-purpose models, it was specifically built to combine writing with on-page SEO optimization. Users were drawn to its promise of a streamlined workflow. Aimed at marketers, SEOs, and content teams, it produces SERP-aligned articles with little manual effort. Its ability to deliver content that\u2019s actually useful and rank-worthy is questionable though. Here\u2019s my experience with it.","date":"2025-06-04T00:00:00.000Z","tags":[],"readingTime":3.69,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Why I Moved On from Surfer SEO (Mostly)","date":"2025-06-04T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Link Building Without Breaking the Bank","permalink":"/blog/6-5-2025-link-building-without-breaking-bank"},"nextItem":{"title":"Vibe Coding Is A New Way to Build","permalink":"/blog/5-21-2025-vibe-coding-democratizes-creativity"}},"content":"Not long ago, Surfer SEO emerged as a leading AI content tool, gaining momentum on ChatGPT. Unlike all-purpose models, it was specifically built to combine writing with on-page SEO optimization. Users were drawn to its promise of a streamlined workflow. Aimed at marketers, SEOs, and content teams, it produces SERP-aligned articles with little manual effort. Its ability to deliver content that\u2019s actually useful and rank-worthy is questionable though. Here\u2019s my experience with it.\\n\\n\x3c!--truncate--\x3e\\n\\n## How Surfer stacks up in AI content generation\\n\\nIn terms of content generation, ChatGPT remains a formidable competitor. Several LLMs come close, particularly Google\u2019s Gemini (it\'s so straightforward!). At Edify Content, the content team relied on Surfer SEO until early 2024. The biggest problem we encountered was its slowness: a 2,000-word article would take up to 20 minutes to generate. More troubling was the predictability of the output and its occasional errors.\\n\\nSurfer SEO also lacked versatility. I frequently found myself taking what Surfer SEO produced and pasting it into ChatGPT. I did this because I needed a more specific prompt to shape the content into what I wanted. Over time, and without really intending to, I stopped using Surfer SEO for content creation altogether.\\n\\nFortunately...\\nThe Surfer SEO tool has continued to evolve. You now have the capability to set content guidelines and produce draft content by analyzing particular rival pages in the SERP. As with many AI writing tools, its strength lies in producing top-of-funnel content. While the text it generates isn\u2019t overtly robotic, it still doesn\u2019t script easily into a particular tone of voice either.\\n\\nOne helpful feature in Surfer is the option to refine a draft by choosing specific questions and topics for the final piece. You can also adjust headings, add or remove keywords, and change up the structure of your piece. While performing these tasks, Surfer keeps tabs with a visible \\"optimization score\\" that reflects how close your piece is to being polished. The scoring system eliminates the guesswork, particularly when you\u2019re adjusting a draft to have greater SEO impact.\\n\\n## Surfer excels at on-page SEO features\\n\\nSurfer SEO excels at SEO content optimization, but you still need to perform basic keyword research. Using advanced Natural Language Processing (NLP), Surfer SEO helps create user intent-aligned content and suggests semantically related keywords so that you can cover topics thoroughly and stay competitive in search.\\n\\nOne notable feature is Surfer SEO\u2019s SERP Analyzer, which examines top-ranking pages for your target keywords. It gives a clearer picture of what users are searching for and why certain pages rank well. The SERP Analyzer highlights the elements that contribute to their performance and offers guidance on how to position your content to compete effectively.\\n\\nI also found Surfer\'s keyword density recommendations helpful. While not groundbreaking, it provided important insights into optimal keyword usage. Without this feature, avoiding keyword stuffing often comes down to guesswork.\\n\\n## Why speed and workflow still matter\\n\\nIn my view, Surfer SEO\'s biggest weakness was its ease of use. The interface is intuitive enough, but the content generation process was far too slow. It dawned on me that I had better plan other tasks while waiting for it to finish. But if Surfer misinterpreted a prompt or my intent, I had to wait through another full run or spend extra time cleaning up irrelevant output. ChatGPT feels much faster and more flexible by comparison. Eventually, i found other content creation tools that did not subject me to such long waits.\\n\\n## Is Surfer SEO still worth it for SEO content?\\n\\n\u200b\u200bUsing a tool to achieve high SEO scores can sometimes negatively impact content quality or readability. With Surfer SEO, that tradeoff is occasionally apparent, particularly with bottom-of-funnel content that requires detailed information. Another issue is that the content requires a significant amount of manual editing to align it with a brand\'s tone or voice.\\n\\nSurfer recently raised prices rather than lower them. If they\'re not careful, they\'ll find themselves in a death spiral, where fewer users incentivizes higher prices to make up the difference.\\n\\nFor now, Surfer SEO remains a leading AI-powered SEO tool for generating SEO content. Several newer players have entered this space, however. Many offer similar functionality at a lower cost or even for free. So I am not convinced that Surfer\u2019s pricing structure makes it a worthwhile tool. At least not for those of us who like to take the initiative and combine tools."},{"id":"/5-21-2025-vibe-coding-democratizes-creativity","metadata":{"permalink":"/blog/5-21-2025-vibe-coding-democratizes-creativity","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/5-21-2025-vibe-coding-democratizes-creativity.md","source":"@site/blog/5-21-2025-vibe-coding-democratizes-creativity.md","title":"Vibe Coding Is A New Way to Build","description":"\u201cVibe coding\u201d sounds like a throwaway phrase. You could be forgiven for not taking it seriously. But for many would-be developers, vibe coding offers genuine creative freedom. With vibe coding, the ability to code is no longer a barrier to software development. LLMs now handle most of the complex construction details.","date":"2025-05-21T00:00:00.000Z","tags":[],"readingTime":2.425,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Vibe Coding Is A New Way to Build","date":"2025-05-21T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Why I Moved On from Surfer SEO (Mostly)","permalink":"/blog/6-4-2025-moving-on-from-surfer-seo"},"nextItem":{"title":"AI Agents Raise Bar on Technical Marketing","permalink":"/blog/5-9-2025-ai-agents-raise-bar"}},"content":"\u201cVibe coding\u201d sounds like a throwaway phrase. You could be forgiven for not taking it seriously. But for many would-be developers, vibe coding offers genuine creative freedom. With vibe coding, the ability to code is no longer a barrier to software development. LLMs now handle most of the complex construction details.\\n\\nWhat\u2019s happening here is a democratization of access. You don\u2019t need coding expertise to create; you need the impulse to do so. If you don\u2019t know JavaScript, Cursor, or another programming language, an LLM can handle it. There\u2019s no mystique here; just initiative and a willingness to experiment.\\n\\n\x3c!--truncate--\x3e\\n\\n## My foray into vibe doding\\n\\nMy own experience speaks to this. When I had to collaborate with a client on GitHub a few months back, I quickly became acquainted with Visual Studio Code\u2019s integrated terminal.\\n\\nShortly afterward, I began using Docusaurus to build a professional website. It was surprisingly intuitive to understand what was needed. And with time, I became more adventurous and willing to overcome coding obstacles. Lucille Ball was right, \u201cthe more things you do, the more you can do\u201d\\n\\nNot being able to write React code from scratch was hardly a problem. With LLMs guiding me, I could follow the structure and purpose of each file, even if I couldn\u2019t explain every line.\\n\\nMy foray into vibe coding might have ended there if I hadn\u2019t stumbled across an article about assembling tools into a full-stack AI-agentic app. It was intriguing enough that I decided to try it myself, with vibe coding as my go-to.\\n\\n## Going the extra mile\\n\\nCreating a website through GitHub is one thing. Building an IT stack that functions as a full application is something else entirely. Think of it as wiring together a series of virtual components using code.\\n\\nI suddenly realized the possibilities for connection were endless. Since my ability to modify proprietary software was limited, I started by exploring open-source projects to jumpstart the process. I set up an Amazon S3 account to store future clickstream data in the cloud.\\n\\nTools I had only heard about, like FastAPI, Render, ngrok, suddenly had a place in my workflow. A whole new world opened up. Without an LLM, wiring all these compnents together would\u2019ve taken months.\\n\\nBut it wasn\u2019t the coding that posed the biggest challenge (Render logs and ChatGPT eliminated that issue). The harder part was thinking through UI decisions. But even here, I\'m reviewing whether to rely on Cursor to provide feedback.\\n\\nThe excitement is just beginning: LLMs that pair with Model Context Protocol (MCP) promise to reshape software. Adding MCP capabilities to softwre isn\'t just an upgrade, it requires a complete rethinking of what software can do. That realization pushed me to explore how I could use these technologies in my own work.\\n\\nI still lie awake at night, thinking through the possibilities of AI-agentic systems and just how far they might go."},{"id":"/5-9-2025-ai-agents-raise-bar","metadata":{"permalink":"/blog/5-9-2025-ai-agents-raise-bar","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/5-9-2025-ai-agents-raise-bar.md","source":"@site/blog/5-9-2025-ai-agents-raise-bar.md","title":"AI Agents Raise Bar on Technical Marketing","description":"Technical content often sits in the background\u2014dense, scattered, and easy to overlook. Yet for engineering firms and industrial manufacturers, it\u2019s anything but optional. CAD drawings, part specifications, safety bulletins, and installation manuals aren\'t just documentation, they\u2019re essential for daily operations.","date":"2025-05-09T00:00:00.000Z","tags":[],"readingTime":3.155,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"AI Agents Raise Bar on Technical Marketing","date":"2025-05-09T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Vibe Coding Is A New Way to Build","permalink":"/blog/5-21-2025-vibe-coding-democratizes-creativity"},"nextItem":{"title":"How Komment.ai Might Change the Way We Write API Documentation","permalink":"/blog/4-29-2025-komment-change-api-docs"}},"content":"Technical content often sits in the background\u2014dense, scattered, and easy to overlook. Yet for engineering firms and industrial manufacturers, it\u2019s anything but optional. CAD drawings, part specifications, safety bulletins, and installation manuals aren\'t just documentation, they\u2019re essential for daily operations.\\n\\nDespite its operational importance, technical content has long been treated as an afterthought in marketing. The focus was often on making PDFs \u201cfindable,\u201d cleaning up metadata, and hoping Google understood what engineers were actually searching for. But that\u2019s changing. A new era is taking shape, one led by AI agents.\\n\\n\x3c!--truncate--\x3e\\n\\n## The problem with static SEO\\n\\nRight now, many industrial firms center their SEO strategies on making static content more visible. They have case studies, compressor manuals, and application bulletins, all of which are relegated to dropdown libraries or buried three clicks deep. Their current workflow is focused on:\\n\\n  - Finding low competition keywords\\n  - Optimizing page titles, headers, and internal links\\n  - Building \\"resource hubs\\" for high intent queries\\n\\nWhile this is a smart strategy- its also somewhat slow. In industries where product specs change at the drop of a hat, new materials are constantly being introduced, and customers demand answers instantly, relying on static SEO alone could easily become a disadvantage.\\n\\n## What AI agents can do\\n\\nAI agents are more than just \\"smarter chatbots.\\" They\'re autonomous systems capable of:\\n\\n  - Ingesting technical documents like installation guides\\n  - Summarizing and interpreting that information to answer user questions\\n  - Providing detailed information through various interfaces, like search bars, product configurators, and customer support dashboards\\n\\nFor example, imagine a prospect browsing a library of technical bulletins or installation guides. Instead of opening multiple PDFs, they could ask:\\n\\n\u201cWhich models meet the updated safety standard for high-pressure environments?\u201d\\n\\nAn AI agent could pull the answer from internal specifications, cite its source, and guide the user to the appropriate product page within seconds.\\n\\n<img src=\\"/img/bot.gif\\" height=\\"150px\\" />\\n\\n\\n## Why this matters for engineering firms\\n\\nEngineering buyers are not leisurely shoppers; they seek definitive responses to specific inquiries and demand them promptly. AI agents bridge the divide between:\\n\\n- What content companies make available\\n- What content potential customers seek to locate\\n\\nSuccess here goes beyond marketing effectiveness. It directly impacts competitiveness. Companies that are able to call up the correct spec sheet, regulatory document, or training video on demand will:\\n\\n- Turn prospects into customers at a faster rate\\n- Save their sales reps from having to engage in time consuming dialogues\\n- Free their marketing teams from having to constantly reformat or rewrite content for different use cases\\n\\n## SEO isn\'t going away, it\'s getting smarter\\n\\nAI agents won\'t replace traditional SEO, they\'ll augment it. In fact, They actually excel in clean, well-structured ecosystems:\\n\\n- Clear navigation menus\\n- Properly tagged documents\\n- Descriptive filenames and alt text\\n- Well-defined product categories and naming conventions\\n\\nIn other words, the better your SEO practices, the more effective your AI driven systems will be in the future.\\n\\n## What forward-thinking firms should do now\\n\\nTechnical marketers should consider taking the following actions, if they haven\'t done so already.\\n\\n1. Thoroughly audit your technical content so you know what you have and where you have it. Make sure everything is findable and nothing important is buried or made inaccessible by poor tagging.\\n\\n2. Tag your assets in a consistent manner in your download library, support documents, and sales materials\\n\\n3. Work with your SEO team to make sure all content is structured for machine readablity.\\n\\n## Final thought\\n\\nIf you already have large quantities of high quality technical literature on hand, the next phase of AI will demand this content be usable at any moment, and in any place. The companies that accomplish this first will achieve superior search rankings and improve their reputation."},{"id":"/4-29-2025-komment-change-api-docs","metadata":{"permalink":"/blog/4-29-2025-komment-change-api-docs","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/4-29-2025-komment-change-api-docs.md","source":"@site/blog/4-29-2025-komment-change-api-docs.md","title":"How Komment.ai Might Change the Way We Write API Documentation","description":"Writing API docs is usually a grind. You flip between code, notes, product specs, and that tiny voice in the back of your head that says, \\"Did I explain that clearly enough?\\" It\u2019s one of those tasks that\u2019s important but exhausting. That\'s where Komment.ai comes in.","date":"2025-04-29T00:00:00.000Z","tags":[],"readingTime":2.02,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"How Komment.ai Might Change the Way We Write API Documentation","date":"2025-04-29T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"AI Agents Raise Bar on Technical Marketing","permalink":"/blog/5-9-2025-ai-agents-raise-bar"},"nextItem":{"title":"How Mintlify is Changing API Documentation","permalink":"/blog/4-20-2025-mintlify-is-changing-api-docs"}},"content":"Writing API docs is usually a grind. You flip between code, notes, product specs, and that tiny voice in the back of your head that says, \\"Did I explain that clearly enough?\\" It\u2019s one of those tasks that\u2019s important but exhausting. That\'s where Komment.ai comes in.\\n\\nKomment.ai takes a swing at the old documentation process by making it more interactive, collaborative, and, frankly, a lot less painful. Instead of bouncing between different tools, Komment.ai lets you layer comments, suggestions, and questions directly on top of the docs or codebase you\u2019re working with. It\'s almost like sticky notes \u2014 but smart ones \u2014 that stay tied to specific sections of the text.\\n\\n\x3c!--truncate--\x3e\\n\\nIf you\'ve ever used Google Docs and loved how people can leave comments right where edits are needed, Komment.ai feels like the natural next step. But it\u2019s built with technical teams in mind. Reviewers can ask questions, suggest changes, or flag confusing parts right alongside the actual content, without needing to send 12 back-and-forth emails or schedule another review meeting.\\n\\nKomment.ai is aiming to do for API documentation what GitHub did for coding workflows \u2014 make it more open, more collaborative, and faster to improve. Instead of one technical writer trying to chase down developers for answers, you can turn documentation into a live conversation. Developers can jump in, clarify tricky points, suggest better examples, or fix errors themselves \u2014 all without breaking the flow.\\n\\nOver time, this could shift what API docs even feel like. They might move from static, one-directional manuals to something more alive \u2014 more like a conversation between the people building the API and the people using it. When questions, edits, and feedback get baked right into the writing process, the end product usually turns out sharper, more accurate, and a whole lot more helpful.\\n\\nPlus, it opens the door for lightweight version control on documentation itself. Instead of treating docs like an afterthought or a separate project, Komment.ai encourages teams to think about them as part of the actual development cycle. You push updates, you improve your docs \u2014 same rhythm.\\n\\nIt\u2019s early, but tools like Komment.ai hint at a bigger shift: making documentation less of a burden and more of a team effort. And when everyone has a hand in shaping the story, the final result usually ends up being something you\'re proud to ship \u2014 not something you rush through at the last minute."},{"id":"/4-20-2025-mintlify-is-changing-api-docs","metadata":{"permalink":"/blog/4-20-2025-mintlify-is-changing-api-docs","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/4-20-2025-mintlify-is-changing-api-docs.md","source":"@site/blog/4-20-2025-mintlify-is-changing-api-docs.md","title":"How Mintlify is Changing API Documentation","description":"For years, API documentation has lived in a strange place\u2014necessary but neglected, important but often out of sync with the product it describes. Developers need docs to build, but maintaining them has traditionally meant choosing between clunky static pages, auto-generated markdown dumps, or overengineered CMS tools that feel more like publishing software than developer platforms.","date":"2025-04-20T00:00:00.000Z","tags":[],"readingTime":2.245,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"How Mintlify is Changing API Documentation","date":"2025-04-20T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How Komment.ai Might Change the Way We Write API Documentation","permalink":"/blog/4-29-2025-komment-change-api-docs"},"nextItem":{"title":"The Tech Powering SaucerSwap","permalink":"/blog/4-10-2025-the-tech-powering"}},"content":"For years, API documentation has lived in a strange place\u2014necessary but neglected, important but often out of sync with the product it describes. Developers need docs to build, but maintaining them has traditionally meant choosing between clunky static pages, auto-generated markdown dumps, or overengineered CMS tools that feel more like publishing software than developer platforms.\\n\\nMintlify is trying to flip that on its head, and with the introduction of **Mintlify MCP (Maintainer Control Panel)**, they\u2019re making a strong case for what modern API docs should look like\u2014and how they should be managed.\\n\\n\x3c!--truncate--\x3e\\n\\n---\\n\\n## What Is Mintlify MCP?\\n\\nMintlify MCP isn\u2019t just a documentation editor. It\u2019s a centralized control panel that sits on top of your existing codebase and documentation, giving you visibility, version control integration, and collaboration tools all in one place.\\n\\nThink of it like this: if your dev team is already keeping docs close to code, MCP makes sure those docs stay accurate, up-to-date, and consistent\u2014without pulling anyone into a separate platform. You can flag outdated endpoints, monitor what\u2019s being used (or ignored), and get insights into how your docs are performing.\\n\\n**Some standout features include:**\\n\\n- **Live feedback from users** (right in the docs)\\n- **GitHub-native change management** (suggest edits, review in PRs)\\n- **Versioned docs tied to deployments**\\n- **Analytics on engagement and usage**\\n\\nIt\'s API documentation with an actual feedback loop\u2014something most dev teams haven\u2019t had before.\\n\\n---\\n\\n## Why this matters\\n\\nAPI documentation often becomes stale the moment it\u2019s written. Products move fast. Endpoints change. Teams ship new features weekly. Unless you have a dedicated tech writer or a very disciplined team, your docs are probably wrong somewhere\u2014and no one wants to be the engineer who stops coding to update docs.\\n\\nMintlify MCP brings automation and accountability into the process. It treats docs like code (with diffs, versioning, and reviews), while also giving maintainers tools to monitor what actually gets read and where people get stuck. That turns documentation from a static reference into a living part of the development cycle.\\n\\nFor API-first products and fast-growing dev tools, this can be a serious unlock. Clean, accurate, and well-managed docs aren\u2019t just nicer\u2014they reduce support tickets, shorten onboarding time, and build trust with external devs.\\n\\n---\\n\\n## Docs are no longer an afterthought\\n\\nThe rise of tools like Mintlify MCP is part of a bigger shift: documentation is becoming infrastructure. It\u2019s not just something you publish once\u2014it\u2019s something you maintain like a product. And if your product *is* an API, then the docs are the front door.\\n\\nWith the Maintainer Control Panel, Mintlify is pushing for a future where dev teams aren\u2019t just writing better documentation\u2014they\u2019re actually empowered to keep it alive."},{"id":"/4-10-2025-the-tech-powering","metadata":{"permalink":"/blog/4-10-2025-the-tech-powering","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/4-10-2025-the-tech-powering.md","source":"@site/blog/4-10-2025-the-tech-powering.md","title":"The Tech Powering SaucerSwap","description":"If you\u2019ve ever wondered what\u2019s going on under the hood of SaucerSwap, here\u2019s the quick version: it\u2019s a decentralized exchange (DEX) built on Hedera\u2014and that choice isn\u2019t just for show. Hedera runs on a technology called Hashgraph, which flips the script on how most blockchains work. The difference has real consequences for how fast, cheap, and reliable a platform like SaucerSwap can be.","date":"2025-04-10T00:00:00.000Z","tags":[],"readingTime":3.31,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"The Tech Powering SaucerSwap","date":"2025-04-10T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How Mintlify is Changing API Documentation","permalink":"/blog/4-20-2025-mintlify-is-changing-api-docs"},"nextItem":{"title":"Top 5 Use Cases for Saucerswap","permalink":"/blog/4-02-2025-top-5-use-cases"}},"content":"If you\u2019ve ever wondered what\u2019s going on under the hood of SaucerSwap, here\u2019s the quick version: it\u2019s a decentralized exchange (DEX) built on Hedera\u2014and that choice isn\u2019t just for show. Hedera runs on a technology called Hashgraph, which flips the script on how most blockchains work. The difference has real consequences for how fast, cheap, and reliable a platform like SaucerSwap can be.\\n\\n\x3c!--truncate--\x3e\\n\\n## Not built on blockchain\\nLet\u2019s back up for a second. Most DEXs reside on Ethereum or similar chains. That means they rely on traditional blockchain architecture: a chain of blocks, added one after the other, with each block holding a bunch of transactions. It\u2019s a tried-and-true system, but it has its limits, with network congestion, high fees, and latency being the big ones.\\n\\nHedera\u2019s Hashgraph works differently. Instead of blocks, it uses a [directed acyclic graph (DAG)](https://hazelcast.com/foundations/distributed-computing/directed-acyclic-graph/)\u2014a data structure where transactions aren\u2019t stacked linearly, but spread out and recorded in parallel. Techies use a [gossip-about-gossip protocol](https://docs.hedera.com/hedera/core-concepts/hashgraph-consensus-algorithms/gossip-about-gossip) here, which means every node quickly shares info with random others. Over time, the whole network has a complete picture of what happened and when, with no mining, leader, or lag.\\n\\n<img src=\\"/img/hashgraph.jpg\\" width=\\"600\\" />\\n\\nThe way Hashgraph handles consensus is key. Every transaction comes with a timestamp, and the network uses a virtual voting mechanism to agree on the order of events. That\u2019s how it moves so fast\u2014thousands of transactions per second, and everything settles in seconds instead of minutes.\\n\\n## Real-time settlement, low fees\\nFor a DEX like SaucerSwap, the Hashgraph technology makes a big difference. Trades get confirmed almost instantly. While [slippage](https://www.investopedia.com/terms/s/slippage.asp) is still largely a factor of liquidity and trading volume, it\'s much lower. And it\'s practically impossible for bots to exploit transaction delay windows. The entire trading experience feels snappier and more predictable, even when the market\u2019s moving fast.\\n\\nThe tech also leads to lower costs. Because no miners compete for block space, gas fees on SaucerSwap are low and predictable. Think in terms of fractions of a cent. The hashgraph tech opens the door for microtransactions and lower-volume activity that would be priced out on other platforms. You don\u2019t have to think twice about trying a swap just to see how a token behaves. And all fees are fixed and denominated in USD-equivalent HBAR.\\n\\nPredictable performance is another upside. Since Hashgraph isn\u2019t battling network congestion in the same way as other chains, you don\u2019t get stuck waiting for a transaction to go through during peak times. The throughput is consistent, and that predictability is worth a lot in a trading environment.\\n\\n## Native token support via HTS\\nSaucerSwap is tightly integrated with [Hedera Token Service (HTS)](https://hedera.com/token-service), which handles the basics\u2014creating tokens, transferring them, freezing or wiping them\u2014without the need for smart contracts. It\u2019s native, fast, and cheap. So, for most token operations, SaucerSwap can skip the overhead of smart contracts and rely on HTS to do the heavy lifting.\\n\\nBut when it comes to more complex functionality\u2014things like routing trades across multiple pools, setting custom logic for incentives, or interacting with other DeFi protocols\u2014SaucerSwap taps into Hedera\u2019s Smart Contract Service. This service is EVM-compatible, meaning developers can write in Solidity and build the kinds of applications they\u2019re used to building on Ethereum. \\n\\nThe difference is that those smart contracts run on Hedera\u2019s Hashgraph under the hood, so you still get low fees and high throughput.\\n\\n## Final thoughts\\nThe entire SaucerSwap setup helps make operations smooth for users and developers. Less friction, fewer surprises. It\u2019s not out to reinvent DeFi, but it shows what DeFi can look like when you build it on something faster and more scalable right from the start. \\n\\nSo while you could use SaucerSwap without knowing a thing about DAGs, Hashgraph, or the rest of the tech stack, understanding what powers the DEX helps explain why it runs the way it does. Building something yourself on the DEX might make you rethink what kind of infrastructure you want under your project."},{"id":"/4-02-2025-top-5-use-cases","metadata":{"permalink":"/blog/4-02-2025-top-5-use-cases","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/4-02-2025-top-5-use-cases.md","source":"@site/blog/4-02-2025-top-5-use-cases.md","title":"Top 5 Use Cases for Saucerswap","description":"While most platforms are still chasing faster, cheaper crypto trading, SaucerSwap\u2019s already delivering. As Hedera\u2019s main DEX, it\u2019s gaining real traction\u2014with over $130 million in total value locked as of early 2025. But it\u2019s not just about token swaps anymore. Traders are using it for staking, governance, liquidity rewards\u2014practical features that are actually getting used.","date":"2025-04-02T00:00:00.000Z","tags":[],"readingTime":3.775,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Top 5 Use Cases for Saucerswap","date":"2025-04-02T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"The Tech Powering SaucerSwap","permalink":"/blog/4-10-2025-the-tech-powering"},"nextItem":{"title":"Why SaucerSwap\'s Quietly Winning in DeFi","permalink":"/blog/3-31-2025-why-saucerswap-is-quietly-winning"}},"content":"While most platforms are still chasing faster, cheaper crypto trading, [SaucerSwap](https://www.saucerswap.finance/)\u2019s already delivering. As Hedera\u2019s main DEX, it\u2019s gaining real traction\u2014with over $130 million in total value locked as of early 2025. But it\u2019s not just about token swaps anymore. Traders are using it for staking, governance, liquidity rewards\u2014practical features that are actually getting used.\\n\\nIf you\u2019ve been wondering why SaucerSwap keeps popping up in DeFi circles, these five use cases make it clear: it\u2019s not just hype.\\n\\n\x3c!--truncate--\x3e\\n\\n## 1: Seamless Token Swaps\\n\\nSaucerSwap does one thing really well: fast, reliable token swaps. It taps into the [Hedera Token Service (HTS)](https://hedera.com/token-service), which means trades settle in about 3 to 5 seconds\u2014no waiting or surprise gas fees. SaucerSwap also prices transaction costs in USD, which keeps fees low and predictable. That\u2019s a big plus for high-volume traders and anyone fed up with Ethereum\u2019s delays and costs.\\n\\nSwapping HBAR for USDC or newer HTS tokens feels smooth, and with SaucerSwap V2\u2019s concentrated liquidity, slippage stays low\u2014even in smaller pools. The smoother experience is helping SaucerSwap pull users away from [Uniswap](https://uniswap.org/) and other Ethereum-based DEXs.\\n\\n\\n## 2: Liquidity Provision and Yield Farming\\n\\nThe process to provide liquidity on SaucerSwap is simple: pick a token pair, deposit both tokens into a pool, and get LP tokens in return. In return, you earn 0.25% of every swap made in that pool. It\u2019s passive, steady, and a big draw for yield-focused users.\\n\\nSaucerSwap has raised the bar with its Liquidity-Aligned Reward Initiative, or LARI. The program offers dual rewards\u2014HBAR and SAUCE\u2014for users who provide liquidity in its V2 concentrated liquidity pools. Instead of traditional LP tokens, your position is represented by an NFT. That NFT can then be staked using the Masterchef contract, allowing you to earn fees and rewards while your liquidity stays active in the pool.\\n\\nThe desire for passive income has attracted long-term investors looking beyond quick gains. It has also added real depth and stability to SaucerSwap\u2019s liquidity. The result is a trading platform where traders can park their assets and earn over time. Growing user commitment is turning it into a central hub for DeFi activity on [Hedera](https://hedera.com/).\\n\\n\\n## 3: Governance via SAUCE Token\\n\\nThe SAUCE token does more than reward users\u2014it opens the door to governance. As SaucerSwap\u2019s decision-making tool, SAUCE gives holders the ability to vote on key protocol updates, including fee structures, liquidity incentives, and reward mechanisms. In 2025, the DAO continues to expand its role, with potential votes on cross-chain integrations like [Axelar](https://axelar.network/) outlined in recent roadmaps.\\n\\nGovernance appeals to users who care about decentralization and want a say in how platforms evolve. As participation grows, SaucerSwap moves further from a top-down model. Community-driven decision-making makes everyday users active stakeholders, giving SaucerSwap an edge no centralized exchange can match\u2014real ownership.\\n\\n\\n## 4: Cross-Chain Liquidity Hub\\n\\nSaucerSwap\u2019s plans to integrate with bridge protocols like [Axelar](https://axelar.network/) and [LayerZero](https://layerzero.network/) will enable seamless asset transfers across chains. In a multi-chain DeFi environment, this partnership helps Hedera connect with ecosystems like Ethereum, Solana, and Avalanche.\\n\\nImagine swapping wrapped BTC from Ethereum directly for HBAR via SaucerSwap at Hedera speeds. The move heralds a major step toward frictionless liquidity. As more users look for efficient, low-fee ways to move assets between chains, SaucerSwap\u2019s cross-chain functionality could make it a go-to hub. It\u2019s bound to lead to a broader user base, deeper liquidity pools, and a more competitive position in the DeFi space.\\n\\n\\n## 5: Community Pool Token Launches\\n\\nSaucerSwap\u2019s community pools introduce a new way to launch tokens\u2014placing distribution directly in user hands rather than under centralized control. Unlike a traditional launchpad, this model lets new projects build liquidity pools that directly reward early supporters.\\n\\nCommunity pools continue to gain traction, with token launches tied to staking xSAUCE or holding ecosystem NFTs such as SAUCELINGs. For example, a new DeFi project might distribute tokens to xSAUCE stakers and offer bonus multipliers to SAUCELING holders. The system rewards participants without relying on gatekeepers.\\n\\n\\n## Wrapping It Up\\n\\nSaucerSwap has come a long way. Token swaps are smooth. Yield farming feels accessible. Governance works. New projects are launching with real community support. Now, with cross-chain growth on the horizon, it\u2019s starting to feel like more than a DEX. Hedera\u2019s speed and low fees give it a competitive edge, but what really stands out is how involved users have become. If you\'re interested, try staking SAUCE or checking out a pool launch. Even a single vote in the DAO can show you what this kind of platform is building toward."},{"id":"/3-31-2025-why-saucerswap-is-quietly-winning","metadata":{"permalink":"/blog/3-31-2025-why-saucerswap-is-quietly-winning","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/3-31-2025-why-saucerswap-is-quietly-winning.md","source":"@site/blog/3-31-2025-why-saucerswap-is-quietly-winning.md","title":"Why SaucerSwap\'s Quietly Winning in DeFi","description":"Using a DEX can feel way harder than it needs to be. One minute you\u2019re making a basic swap. The next, gas fees eat half your gains, your transaction gets front-run, and you\'re stuck navigating a UI that looks like it hasn\u2019t been updated since 2015. It\'s enough to make you wonder if DeFi\'s worth the hassle.  That\u2019s usually when someone drops, \u201cHave you looked at SaucerSwap?\u201d Usually followed by, \u201cWait\u2014the one on Hedera? The chain with SWIFT on the council?\u201d","date":"2025-03-31T00:00:00.000Z","tags":[],"readingTime":4.965,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Why SaucerSwap\'s Quietly Winning in DeFi","date":"2025-03-31T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Top 5 Use Cases for Saucerswap","permalink":"/blog/4-02-2025-top-5-use-cases"},"nextItem":{"title":"Getting Started with SaucerSwap -- A Beginner\'s Guide","permalink":"/blog/3-27-2025-getting-started-with-saucerswap"}},"content":"Using a DEX can feel way harder than it needs to be. One minute you\u2019re making a basic swap. The next, gas fees eat half your gains, your transaction gets front-run, and you\'re stuck navigating a UI that looks like it hasn\u2019t been updated since 2015. It\'s enough to make you wonder if DeFi\'s worth the hassle.  That\u2019s usually when someone drops, \u201cHave you looked at [SaucerSwap](https://www.saucerswap.finance/)?\u201d Usually followed by, \u201cWait\u2014the one on [Hedera](https://hedera.com/)? The chain with [SWIFT](https://www.swift.com/) on the council?\u201d\\n\\nSaucerSwap isn\u2019t trying to reinvent the wheel. It\u2019s just quietly building a faster, cleaner, less painful way to trade\u2014staking, farming, and all. And if you\u2019re tired of friction every time you try to move a few tokens, it might be worth a look. Let\u2019s explore what makes SaucerSwap different\u2014and why it could be one of the more interesting DEXs to watch.\\n\\n\x3c!--truncate--\x3e\\n\\n## Hedera Power: The Secret Behind SaucerSwap\\n\\nSaucerSwap doesn\u2019t play by the usual DeFi rules. It\u2019s built on [Hedera](https://hedera.com/)\u2014a network that takes a different approach to speed and cost. Unlike traditional blockchain tech, Hedera uses a system called hashgraph, which handles thousands of transactions per second and keeps fees at about a penny or less. Compare that to [Ethereum](https://ethereum.org/), where gas fees can spike unexpectedly and drain your wallet fast. If you\u2019re looking to swap tokens or earn yield without burning cash, SaucerSwap\u2019s low-cost efficiency is a smart choice.\\n\\nHedera also brings some credibility to the table. The council that governs Hedera includes prominent names like [Google](https://www.google.com/), [IBM](https://www.ibm.com/), and [SWIFT](https://www.swift.com/)\u2014the same SWIFT that powers much of the global banking system. That\u2019s not hype; institutional backing sets it apart from many other blockchain platforms.\\n\\n\\n## Smooth, No-Nonsense Swaps\\n\\nAt its core, SaucerSwap helps you conduct token swaps. It\u2019s a decentralized exchange (DEX), which means you\u2019re trading directly from your wallet\u2014no intermediaries get in the way. But what makes it stand out is how seamless the experience is. Hedera\u2019s high throughput and low latency mean swaps typically settle in seconds, so you can execute trades fast\u2014no waiting around.\\n\\nYou don\u2019t have to wait for block confirmations, and your transaction won\u2019t get held up behind others in a queue. If you\u2019ve ever had a trade hijacked by front-running bots\u2014those automated programs that jump ahead of your order\u2014Hedera\'s structure blocks that from happening. Rather than rely on a mempool, which can expose transactions before they finalize, Hedera processes trades in a way that prevents those tactics entirely. The result is a faster, more predictable trading experience\u2014especially for anyone frustrated by the congestion common to Ethereum-based platforms.\\n\\n\\n## Staking and Farming, Simplified\\n\\nBeyond token swaps, SaucerSwap makes staking and yield farming easy to navigate. You can stake your SAUCE tokens in just a few clicks and start earning rewards\u2014no complex setup or deep crypto knowledge needed. The platform also stakes all HBAR in its liquidity pools directly on the Hedera network, earning additional rewards that it converts to SAUCE and shares with stakers. It\u2019s passive income on autopilot: set it, forget it, and watch your holdings grow.\\n\\nYield farming gives you a bit more flexibility. Pair tokens, add them to liquidity pools, and earn both trading fees and SAUCE rewards. The interface is clean and intuitive\u2014no clutter, no confusing menus, and nothing sketchy. It\u2019s a set-it-and-forget-it setup that lets your holdings grow over time.\\n\\n\\n## Transparent Fees That Stay Low\\n\\nNobody likes watching fees chip away at gains. SaucerSwap keeps transaction costs predictable thanks to Hedera\u2019s fixed, USD-based fee structure. You know exactly what you\u2019ll pay before you hit confirm\u2014no surprises. \\n\\nDuring periods of high network activity, Ethereum gas fees can spike dramatically, making trades on other DEXs more expensive. SaucerSwap avoids this problem entirely by offering low fees that stay around a fraction of a cent. If you\u2019re a frequent trader or work with smaller positions, you can trade confidently, knowing costs won\u2019t chip away at your gains.\\n\\n### Feature Comparison Table\\n\\n\\n## What SaucerSwap\u2019s Building Behind the Scenes\\n\\nSaucerSwap isn\u2019t standing still. While most DEXs are busy chasing hype, it\'s steadily building out features that make trading smarter and more accessible. Here\u2019s a look at what\u2019s new and coming down the pipeline\u2014and why it matters.\\n\\n### Smarter Trading Tools for Real Traders\\n\\nSaucerSwap is rolling out advanced tools like on-chain limit orders and stop-loss functionality\u2014features that let you set exact price points for trades. Its goal is to make trading more intentional, which means fewer emotional decisions and more control. Dollar-cost averaging (DCA) is also in the works, so you\u2019ll be able to automate regular buys and take the edge off market swings. These features rarely show up in basic DEXs\u2014but SaucerSwap\u2019s baking them in for users who want more control.\\n\\n### Cross-Chain Ready\\n\\nCross-chain integration with [Axelar](https://axelar.network/) and [LayerZero](https://layerzero.network/) means SaucerSwap isn\u2019t limited to Hedera. You\u2019ll be able to move assets between blockchains\u2014like bringing over tokens from Ethereum\u2014without leaving the platform. That opens the door to more liquidity, more users, and far more trading possibilities. For serious DeFi users, it also means flexibility. For institutions, it shows a platform that\u2019s thinking ahead.\\n\\n### Security That Is Actually Built In\\n\\nSecurity and compliance aren\u2019t bolted on after the fact. SaucerSwap is integrating with tools like [Chainalysis](https://www.chainalysis.com/) and [Chainabuse](https://www.chainabuse.com/), as detailed in its January 2025 roadmap. This feature matters if you\u2019re thinking long-term, especially as regulators pay more attention to crypto. With institutional-grade monitoring and transparency, the platform isn\u2019t just trying to grow fast; it\u2019s doing it the right way.\\n\\n## Wrapping It Up\\n\\nSaucerSwap hits a rare combo: speed, affordability, and simplicity. It\u2019s also built on Hedera\u2014a blockchain with real weight behind it. The tech runs smoothly, the experience is intuitive, and with SWIFT involved, there\u2019s a clear signal that this could scale far beyond the usual DeFi crowd. Whether you\u2019re swapping, staking, or farming, SaucerSwap hits that rare balance between simplicity and capability. Try a few trades with HBAR and see why this DEX is quietly gaining ground in the DeFi space."},{"id":"/3-27-2025-getting-started-with-saucerswap","metadata":{"permalink":"/blog/3-27-2025-getting-started-with-saucerswap","editUrl":"https://github.com/johnpottergr/johnpottergr.github.io/blog/3-27-2025-getting-started-with-saucerswap.md","source":"@site/blog/3-27-2025-getting-started-with-saucerswap.md","title":"Getting Started with SaucerSwap -- A Beginner\'s Guide","description":"Welcome to SaucerSwap!","date":"2025-03-27T00:00:00.000Z","tags":[],"readingTime":4.075,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Getting Started with SaucerSwap -- A Beginner\'s Guide","date":"2025-03-27T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Why SaucerSwap\'s Quietly Winning in DeFi","permalink":"/blog/3-31-2025-why-saucerswap-is-quietly-winning"}},"content":"## Welcome to SaucerSwap!\\n\\n[SaucerSwap](https://www.saucerswap.finance/) is a top-tier decentralized exchange (DEX) built on the [Hedera](https://hedera.com/) network. It\u2019s a platform where you can trade cryptocurrencies like HBAR and other Hedera Token Service (HTS) tokens quickly, securely, and with fees that won\u2019t break the bank. Whether you\u2019re looking to swap tokens, provide liquidity, or stake your assets, this guide will help you take your first steps. No middlemen, no hassle\u2014just you and your crypto!\\n\\n\x3c!--truncate--\x3e\\n\\n## What You\u2019ll Need Before You Begin\\n\\nTo get started, you\u2019ll need a few essentials:\\n\\n- **A Hedera Wallet**: SaucerSwap works with wallets compatible with the Hedera network, such as [HashPack](https://hashpack.app/) or [Blade](https://bladewallet.io/). These wallets store your HBAR and tokens securely.\\n- **HBAR**: The native cryptocurrency of Hedera, HBAR is required to pay for transaction fees on SaucerSwap. You can purchase HBAR on exchanges like [Binance](https://www.binance.com/), [Coinbase](https://www.coinbase.com/), or [KuCoin](https://www.kucoin.com/) and transfer it to your wallet.\\n  Alternatively, SaucerSwap offers a Coinbase Onramp, allowing you to buy and transfer HBAR directly within the platform. Simply navigate to the *Swap* page and select the *Buy* tab next to *Swap* to get started.\\n- **A Web Browser**: Access SaucerSwap through a browser like [Chrome](https://www.google.com/chrome/) or [Firefox](https://www.mozilla.org/firefox/) by visiting [https://www.saucerswap.finance/](https://www.saucerswap.finance/).\\n\\n\\n## Step 1: Set Up Your Hedera Wallet\\n\\n1. **Download a Wallet**: Visit [https://hashpack.app/](https://hashpack.app/) (for HashPack) or [https://bladewallet.io/](https://bladewallet.io/) (for Blade) and follow the instructions to install the wallet as a browser extension or mobile app.\\n2. **Create Your Wallet**: Open the app, click \u201cCreate Wallet,\u201d and follow the prompts. You\u2019ll get a seed phrase\u2014a 12- or 24-word sequence. Write it down and store it somewhere safe (never share it!).\\n3. **Add HBAR**: Send HBAR from an exchange to your wallet\u2019s Hedera account ID (looks like `0.0.xxxxxx`)\u2014grab it from your wallet app. Double-check the address, as mistakes are permanent. Expect it to arrive in minutes!\\n\\n\\n## Step 2: Connect to SaucerSwap\\n\\n1. **Visit the Site**: Go to [https://www.saucerswap.finance/](https://www.saucerswap.finance/).\\n2. **Connect Your Wallet**: Click \u201cConnect Wallet\u201d in the top-right corner. Select your wallet (e.g., HashPack or Blade) from the options. Approve the connection in your wallet app when prompted.\\n\\n![A wallet screen](/img/connect-your-wallet.jpg)\\n\\n4. **Verify Connection**: Once connected, you\u2019ll see your wallet\u2019s HBAR balance displayed on the SaucerSwap interface.\\n\\n\\n## Step 3: Start Swapping Tokens\\n\\n1. **Navigate to Swap**: On the homepage, find the \u201cSwap\u201d section (it\u2019s front and center!).\\n2. **Choose Tokens**: Select the token you want to swap from (e.g., HBAR) and the token you want to receive (e.g., SAUCE or USDC). If you don\u2019t see a token, you may need to add it manually using its token ID (available on Hedera explorers like [HashScan](https://hashscan.io/)).\\n3. **Enter Amount**: Input how much you want to swap. SaucerSwap will calculate the amount you\u2019ll receive, factoring in a small fee (denominated in USD, paid in HBAR).\\n4. **Adjust Slippage (Optional)**: Click the gear icon to tweak slippage tolerance (e.g., 0.5%) if you\u2019re worried about price changes during the transaction\u2014it\u2019s the max price shift you\u2019ll accept to protect against losses from market moves. For volatile tokens, bump it to 1\u20133%.\\n5. **Swap It**: Click \u201cSwap,\u201d review the details, and confirm the transaction in your wallet. In seconds, your new tokens will appear!\\n\\n![A swap-it screen](/img/swap-it.jpg)\\n\\n## Step 4: Explore More Features\\n\\n- **Add Liquidity**: If you want to earn fees, go to the \u201cLiquidity\u201d tab, pick a token pair (e.g., HBAR/USDC), and supply equal values of both tokens to a pool. You\u2019ll get LP tokens representing your share\u2014think of them as a receipt. These earn a cut of trading fees (check the pool\u2019s APR on the site), which you can claim later by removing liquidity.\\n\\n ![A add liquidity screen](/img/add-liquidity.jpg)\\n\\n- **Stake SAUCE**: If you own SAUCE tokens, you can stake them to earn rewards. Head to the \u201cStake\u201d section, deposit them into the Infinity Pool, and earn xSAUCE, which grows in value over time as a reward.\\n\\n\\n\\n- **Check Your Progress**: Use Hedera explorers like [https://hashscan.io/](https://hashscan.io/) to track your transactions and balances.\\n\\n\\n## Tips for Beginners\\n\\n- **Start Small**: Test with a small amount of HBAR or tokens to get comfortable.\\n- **Watch Fees**: SaucerSwap fees are low and in USD (paid in HBAR), but ensure you have enough HBAR for transactions.\\n- **Stay Safe**: Never share your seed phrase or private keys. SaucerSwap is self-custody, meaning you control your assets\u2014no one else.\\n\\n\\n## Troubleshooting\\n\\n- **Stuck?** If a swap fails, check your HBAR balance for fees (a few cents usually does it).\\n- **Wallet not connecting?** Refresh the page or reinstall the extension.\\n- **Still lost?** Hit up the [Discord](https://discord.com/invite/saucerswap)! Or visit our [Tutorials page](https://docs.saucerswap.finance/tutorials).\\n\\n\\n## Why SaucerSwap?\\n\\nSaucerSwap stands out with Hedera\u2019s fast transaction speeds, fair pricing (no MEV attacks like on Ethereum), and a user-friendly design. Whether you\u2019re trading, staking, or providing liquidity, it\u2019s a secure gateway to decentralized finance (DeFi).\\n\\n\\n## Need Help?\\n\\nJoin the SaucerSwap community for support:\\n\\n- **Discord**: [https://discord.com/invite/saucerswap](https://discord.com/invite/saucerswap)\\n- **Twitter**: [https://twitter.com/SaucerSwapLabs](https://twitter.com/SaucerSwapLabs)\\n- **Docs**: [https://docs.saucerswap.finance/](https://docs.saucerswap.finance/)"}]}}')}}]);